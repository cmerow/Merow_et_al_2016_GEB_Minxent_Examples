timate,method="BFGS",print.level=1,iterlim=2500,finalHessian=TRUE);est.parms=exp(out$estimate); est.parms; parms;se=sqrt(diag(vcov(out)));  	estimates[rep,]=est.parms;ses[rep,]=se; z=(log(est.parms)-log(parms))/se;  converged[rep] = (summary(out)$returnMessage=="successful convergence ")cat(rep,z,"\n"); }
nrep=1; estimates=ses=matrix(0,nrep,length(parms)); converged=rep("0",nrep); # simulate population data from true parameters for(rep in 1:nrep) {	Pop[[1]]=rnorm(100,mean=3,sd=0.8); 	plot(Pop[[1]],rep(0,length(Pop[[1]])),xlim=c(-1,15),ylim=c(0,4),pch="+");  	for(j in 2:5) {			Pop[[j]]=xnew(Pop[[j-1]],parms); P1=Pop[[j]]; 			points(P1,rep(j-1,length(P1)),pch="+");  			text(max(P1)+0.5,j-1,labels=as.character(length(P1)),col="blue",cex=1)	}				# maximize the likelihood, using repeated Nelder-Mead to hopefully find the global	# minimum, and then BFGS to hone in on the minimum and compute the Hessian 	verbose.objfun=FALSE;	out=maxLik(logLikfun,start=log(parms),method="NM",print.level=1, iterlim=2500,finalHessian=FALSE);	out=maxLik(logLikfun,start=out$estimate,method="NM",print.level=4, iterlim=2500,finalHessian=FALSE);	out=maxLik(logLikfun,start=out$estimate,method="NM",print.level=4, iterlim=2500,finalHessian=FALSE);	out=maxLik(logLikfun,start=out$estimate,method="BFGS",print.level=1, iterlim
=2500,finalHessian=TRUE);	est.parms=exp(out$estimate); est.parms; parms;	se=sqrt(diag(vcov(out)));  		estimates[rep,]=est.parms;	ses[rep,]=se; 	z=(log(est.parms)-log(parms))/se;  	converged[rep] = (summary(out)$returnMessage=="successful convergence ")	cat(rep,z,"\n"); }
plot(Pop[[1]],rep(0,length(Pop[[1]])),xlim=c(-1,15),ylim=c(0,4),pch="+");
for(j in 2:5) {			Pop[[j]]=xnew(Pop[[j-1]],parms); P1=Pop[[j]]; 			points(P1,rep(j-1,length(P1)),pch="+");  			text(max(P1)+0.5,j-1,labels=as.character(length(P1)),col="blue",cex=1)	}
Pop
?vcov
est.parms
out$estimate
se=sqrt(diag(vcov(out)));
str(out)
out$hessian
z
?save.image
out
log(parms)
log(est.parms)
se
LogLik.g=function(size,sizeNext,parms) {  mu <- parms['mu']  sigma <- param['sigma']  N=length(x)  ll <- -0.5*N*log(2*pi) - N*log(sigma) - sum(0.5*((sizeNext-size) - mu)^2/sigma^2)  ll}
parms
LogLik.g=function(size,sizeNext,parms) {  mu <- parms['mu']  sigma <- parms['sigma']  N=length(x)  ll <- -0.5*N*log(2*pi) - N*log(sigma) - sum(0.5*((sizeNext-size) - mu)^2/sigma^2)  ll}parmssize=6; sizeNext=7LogLik.g(size,sizeNext,parms)
LogLik.g=function(size,sizeNext,parms) {  mu <- parms['mu']  sigma <- parms['sigma']  N=length(size)  ll <- -0.5*N*log(2*pi) - N*log(sigma) - sum(0.5*((sizeNext-size) - mu)^2/sigma^2)  ll}
LogLik.g(size,sizeNext,parms)
dnorm(sizeNext-size,parms["mu"],parms["sigma"])
log(dnorm(sizeNext-size,parms["mu"],parms["sigma"]))
?dlogis
?maxLik
?logit
?glm
LogLik.s=function(size,surv,parms) {	lp=parms['q'] # survival is currently a size independent constant	# lp=mX %*% vBeta for making it a regression  sum( surv*(lp - log(1+exp(lp)))  + (1-surv)*(-log(1 + exp(lp))) )  }
?rbinom
d.tmp=data.frame(size=rep(1e4,1e3),surv=rbinom(1e3,.8))
ting applyThresholdRule='Fixed cumulative value 1' or some other relevant value#CM: this is the version we'll use if we do species swd# 	system(paste0('java -mx4024m -jar ',maxentdir,# 		' nowarnings noprefixes -a -z outputdirectory=',maxdir,# 		" samplesfile=", inputCSV,# 		" environmentallayers=",bgdir,'/bg_swd.csv',# 		' outputformat=raw writemess=FALSE',# 		' projectionlayers=', envdir, ' maximumbackground=30000 nothreshold'))#CM: this is the version we'll use if we skip swdinputCSV='/Users/ctg/Documents/BIEN_models/test_dir/SpeciesCSVs/Abies_balsamea.csv'# t1=read.csv('/Users/ctg/Documents/BIEN_models/test_dir/SpeciesCSVs/Abies_balsamea.csv')# inputCSV='/Users/ctg/Documents/BIEN_models/test_dir/out/Maxent/Maxent_BioclimSpatial/tmp/Abies_balsamea.csv'# t2=read.csv('/Users/ctg/Documents/BIEN_models/test_dir/out/Maxent/Maxent_BioclimSpatial/tmp/Abies_balsamea.csv')startdate=proc.time()	system(paste0('java -mx4024m -jar ',maxentdir,		' nowarnings noprefixes -a -z outputdirectory=',maxdir,
" samplesfile=", inputCSV,		" environmentallayers=",envdir,		' outputformat=raw writemess=FALSE',		' projectionlayers=', envdir, ' maximumbackground=30000 nothreshold'))elapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))#
print(paste("Finished MAXENT model for", species))print('Evaluating the Maxent Model')# CM: we don't need these until we do some real evaluation# CM: # Load the background data for sampling# CM: bg <- read.csv(file=paste0(bgdir, '/bg_swd.csv'))# CM: # Sample background data to 10% of total(3000)# CM: bg1 <- bg[sample(nrow(bg), 3000), ]#
#retrive maxent model outputr <- raster(paste0(maxdir,'/',species, '_Env.asc'))print(paste0('Loading environmental data from ', envdir))predictors <- stack(list.files(path=envdir, pattern='asc', full.names=TRUE))# CM: I don't see the point in these evaluation statistics. maxent already reports some of them, so just read them in from the maxentResults.csv associated with each run. evenually, when i've developed a useful way to do this, we'll do some evaluation, but that's a ways off.# CM: it would be great to just record the entire maxetnResults file. but if that's an issue, for this evaluation stuff i'd record the columns named Regularized training gain,	Unregularized training gain, Training AUC# CM: if we keep random test points=20 (pending email discussion). record the same statistics for the testing data from the maxentResults.csv file.# print('Environmental data loaded evaluating...')# # Extract the maxent values for a test subset of the presence points# pts.test <- extract(r, pts.test[,1])
time for this operationelapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))#
# CM: you'll have to omit a number of these if we don't calculate them any more.# record the model run results to the statistics filemySpecies <- paste(species) # reformat the species name for CSV outputnotes <- "Ok"m[1,] <- c(mySpecies,	maxentModelType,	cellsize01TP,	r.rasterThresh01TP.area,	r.rasterThresh01TP.Clip.area,	r.tps,	r.fps,	r.tns,	r.fns,	r.sensitivity,	r.specificity,	r.totaccur,	r.auc,	r.corr,	r.thresh01TP,	shpWrite,        jpgWrite,	elapsedTime[3],	notes)# write the maxent statistics to CSV filfilename <- paste(statdir, "/", species, "_", maxentModelType, ".csv", sep="")print(paste0("Writing statisics to ", filename))write.csv(m, file=filename)filename <- paste(threshstatdir, "/", species, "_", maxentModelType, "_Thresholds.csv", sep="")print(paste0("Writing thresholds to ", filename))write.csv(r.thresholds, file=filename)# finishedprint(paste("Finished MAXENT model for", species))#} else {#print(paste("Skipping", basename(speciesCSV), "- model already run."
))#}#end id already exists}#end function#-------------------#p------ END --------#-------------------#-------------------#------ TEST -------#-------------------#uncomment to test# basedir <- "/home/02897/npcasler/test"# speciesCSV <- "/home/02897/npcasler/test/SpeciesCSVs/5Points/Abies_amabilis.csv"# outputdir <- "/home/02897/npcasler/test/output"# useCustomJunkPath <- FALSE# # myResult <- computeSDM_BioclimSpatial(speciesCSV, basedir, outputdir, useCustomJunkPath)# if(class(myResult) == "try-error") {# 	print("Error running CreateSDM_Bioclim function")# } else {# 	print("Completed processing")# }
---- FUNCTION----#------------------# CM: added maxent path so others can use on their systems# CM: computeSDM_BioclimSpatial <- function(speciesCSV, basedir, outputdir, customJunkPath) {computeSDM_BioclimSpatial <- function(speciesCSV, basedir, outputdir, customJunkPath,maxentdir) {# Get the start time of the functionstartdate=proc.time()print(paste0('Process started at ', proc.time()))# naming is legacy of models compared in bien2maxentModelType <- "Maxent_BioclimSpatial"# get the path of script executionworkingdir <- basedir# set the path to the environmental dataenvdir <- paste(basedir, "/Env", sep="")bgdir <- paste(basedir, "/bg", sep="")maxdirname <- maxentModelType# CM: we don't need this for now since we can just read in the maxentResults file# create a matrix to hold the model resultsm <- matrix(nrow=0,ncol=5,byrow=TRUE)colnames(m) <- c(	"species",# 	"maxentModelType",# 	"cellSize",# #	"cellAreaFixed",# #	"cellAreaMaxSS",# #	"cellAreaBalSS",# #	"cellAreaMaxKappa",#
 #	"cellAreaMTP",# 	"cellArea01TP",# 	"cellArea01TPClip",# #	"cellArea05TP",# #	"cellArea10TP",# 	"truePositives",# 	"falsePositives",# 	"trueNegatives",# 	"falseNegatives",# 	"Sensitivity",# 	"Specificity",# 	"totalAccuracy",# 	"aucScore",# 	"correlationScore",# #	"maxKappaScore",# #	"thresholdFixed",# #	"thresholdMaxSS",# #	"thresholdBalSS",# #	"thresholdMaxKappa",# #	"thresholdMTP",# 	"threshold01TP",# #	"threshold05TP",# #	"threshold10TP",	"shapefileWritten",  "jpgWritten",	"elapsedTime",	"notes")m <- transform(m, species = as.character(species),	# maxentModelType = as.character(maxentModelType),	# 	cellSize = as.numeric(cellSize),# #	cellAreaFixed = as.numeric(cellAreaFixed),# #	cellAreaMaxSS = as.numeric(cellAreaMaxSS),# #	cellAreaBalSS = as.numeric(cellAreaBalSS),# #	cellAreaMaxKappa = as.numeric(cellAreaMaxKappa),# #	cellAreaMTP = as.numeric(cellAreaMTP),# 	cellArea01TP = as.numeric(cellArea01TP),# 	cellArea01TPClip = as.numeric(cellArea01TPClip),# #	cellArea05T
P = as.numeric(cellArea05TP),# #	cellArea10TP = as.numeric(cellArea10TP),# 	truePositives = as.numeric(truePositives),# 	falsePositives = as.numeric(falsePositives),# 	trueNegatives = as.numeric(trueNegatives),# 	falseNegatives = as.numeric(falseNegatives),# 	Sensitivity = as.numeric(Sensitivity),# 	Specificity = as.numeric(Specificity),# 	totalAccuracy = as.numeric(totalAccuracy),# 	aucScore = as.numeric(aucScore),# 	correlationScore = as.numeric(correlationScore),# #	maxKappaScore = as.numeric(maxKappaScore),# #	thresholdFixed = as.numeric(thresholdFixed),# #	thresholdMaxSS = as.numeric(thresholdMaxSS),# #	thresholdBalSS = as.numeric(thresholdBalSS),# #	thresholdMaxKappa = as.numeric(thresholdMaxKappa),# #	thresholdMTP = as.numeric(thresholdMTP),# 	threshold01TP = as.numeric(threshold01TP),# #	threshold05TP = as.numeric(threshold05TP),# #	threshold10TP = as.numeric(threshold10TP),	elapsedTime = as.character(elapsedTime),	shapefileWritten = as.character(shapefileWritten),        jpgWr
itten = as.character(jpgWritten),	notes = as.character(notes))#
# Set the projection definitionmyprj = "+proj=laea +lat_0=15 +lon_0=-80 +x_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs +towgs=0,0,0"# check if the species csv file existsif (file.exists(speciesCSV) == FALSE) {	errmsg <- paste("Input species CSV file", speciesCSV, "does not exist.")	stop(errmsg)}# check if the environmental raster directory existsif (file.exists(envdir) == FALSE) {	errmsg <- paste("Environmental layers directory", envdir, "does not exist.")	stop(errmsg)}# check to see if the base output directory existsif (file.exists(outputdir) == FALSE) {	errmsg <- paste("Output directory", outputdir, "does not exist.")	stop(errmsg)}# Check for output file directories, create them if they do not existmaxdir <- paste(outputdir, "/Maxent/", sep='')if (file.exists(maxdir) == FALSE) {dir.create(maxdir)}maxdir <- paste(outputdir, "/Maxent/", maxdirname, sep="")if (file.exists(maxdir) == FALSE) {dir.create(maxdir)}#set the path to the tmp folder to hold intermediate outputsmaxTmpDi
CSV), '.csv')print(paste("Reading species occurrence records in", basename(speciesCSV)))# Kfold partitioning - withold 20% of the sample for testing # CM: we don't need to ask maxent to do the evaluation# CM: NOT NEEDED, AS FAR AS I CAN TELL # CM: pts <- read.csv(file=speciesCSV, header=TRUE)# CM: elapsedTime <- proc.time() - startdate# CM: print(paste0("elapsedTime: ", elapsedTime[3]))# CM: # fold <- kfold(pts, k=5)# CM: # pts.test <- pts[fold == 1, ]# CM: # pts.train <- pts[fold != 1, ]# CM: print("Species points class is")# CM: print(class(pts))#check to see if the model has already been run#filename <- paste(maxdir, '/', species, '_', maxentModelType, ".csv", sep="")#if (file.exists(filename) == FALSE)  {inputCSV <- paste0(maxTmpDir, species, '.csv')copycmd <- paste0("cut -f2- -d ',' ",speciesCSV, " > ", inputCSV)print(copycmd)system(copycmd)elapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))#
print(paste("Creating Maxent", maxentModelType, "Model for", species))#get the starting time for this operationelapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))	# CM: changed a few settings#			1. added maxent path	# 		2. removed random testpoints# 	system(paste0('java -mx4024m -jar ',# 		'/home/02897/npcasler/maxent.jar nowarnings noprefixes -a -z outputdirectory=',maxdir,# 		" samplesfile=", inputCSV,# 		" environmentallayers=",bgdir,'/bg_swd.csv',# 		' randomtestpoints=20 outputformat=raw writemess=FALSE',# 		' projectionlayers=', envdir, ' maximumbackground=30000'))# CM: remove random test points=20 (pending email discussion).# CM: it is probably easiest to just remove the unused predictors from the environmental directories layer (see email discussion) but you could manually omit all the predictors in the maxent call with -N predictor_name# CM: note that if we are really are only get the binary map and toss raw output, maxent can do this for us by set
ting applyThresholdRule='Fixed cumulative value 1' or some other relevant value#CM: this is the version we'll use if we do species swd	system(paste0('java -mx4024m -jar ',maxentdir,		' nowarnings noprefixes -a -z outputdirectory=',maxdir,		" samplesfile=", inputCSV,		" environmentallayers=",bgdir,'/bg_swd.csv',		' outputformat=raw writemess=FALSE',		' projectionlayers=', envdir, ' maximumbackground=30000 nothreshold'))elapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))#
print(paste("Finished MAXENT model for", species))print('Evaluating the Maxent Model')# CM: we don't need these until we do some real evaluation# CM: # Load the background data for sampling# CM: bg <- read.csv(file=paste0(bgdir, '/bg_swd.csv'))# CM: # Sample background data to 10% of total(3000)# CM: bg1 <- bg[sample(nrow(bg), 3000), ]#
#retrive maxent model outputr <- raster(paste0(maxdir,'/',species, '_Env.asc'))print(paste0('Loading environmental data from ', envdir))predictors <- stack(list.files(path=envdir, pattern='asc', full.names=TRUE))# CM: I don't see the point in these evaluation statistics. maxent already reports some of them, so just read them in from the maxentResults.csv associated with each run. evenually, when i've developed a useful way to do this, we'll do some evaluation, but that's a ways off.# CM: it would be great to just record the entire maxetnResults file. but if that's an issue, for this evaluation stuff i'd record the columns named Regularized training gain,	Unregularized training gain, Training AUC# CM: if we keep random test points=20 (pending email discussion). record the same statistics for the testing data from the maxentResults.csv file.# print('Environmental data loaded evaluating...')# # Extract the maxent values for a test subset of the presence points# pts.test <- extract(r, pts.test[,1])
# # # print("Pts.test loaded")# #Extract the maxent values for the background samples# bg.test <- extract(r, bg1[,1])# print("bg.test loaded")# # #evaluate the presence and absence points# e1 = evaluate(p=pts.test, a=bg.test)# elapsedTime <- proc.time() - startdate# print(paste0("elapsedTime: ", elapsedTime[3]))# print(e1)# # get the number of presences# r.numpres <- e1@np# # # get the number of absences# r.numabs <- e1@na# # # get the AUC# r.auc <- e1@auc# # # get the correlation# r.corr <- e1@cor# # # get the kappa score - maximum kappa# #r.kappa <- which.max(e1.kappa)# # # get the true/false positive/negative totals from the confusion tables# r.tps <- sum(e1@confusion[,1])# r.fps <- sum(e1@confusion[,2])# r.tns <- sum(e1@confusion[,3])# r.fns <- sum(e1@confusion[,4])# # # get the total points# totpts <- r.tps + r.fps + r.tns + r.fns# # # get the sensitivity# r.sensitivity <- r.tps / (r.tps + r.fns)# # # get the specificity# r.specificity <- r.fps / (r.fps + r.tns)
# # # get the overall accuracy (correct/total)# r.totaccur <- (r.tps + r.tns) / totpts# CM: if we wanted to use a different trheshold rule we can just get these from the maxentResults.csv file, and avoid all the things that depend on evaluate. but if we want 1% training quantile, we have to calucalate that ourselves.# get all the thresholds # r.thresholds <- e1@t# get the 01% training presence threshold# CM: read in the prediction file and calculate.tmp=read.csv(paste0(maxdir,species,'_samplePredictions.csv')r.thresh01TP <- quantile(tmp[tmp$Test.or.Train=='train','Raw.prediction'],.01)# CM: not needed unless we calculate stats ourselves: r.thresh01TP <- quantile(e1@presence, 0.01)# get a raster of the cells that equal or exceed the threshold valuer.rasterThresh01TP <- (r >= r.thresh01TP)### run the advanced clipping method on the thresholded raster #### get patches in the raster layerclmp <- clump(r.rasterThresh01TP)# insteadof rasterizing polygons, you can use distance# or dustanceFro
mPonts, we haven't checked into which is faster <<-- CHECK INTO THIS#first need to get the points for the cellspoints <-xyFromCell(r, pts[,1])d <- distanceFromPoints(r, points)distanceThreshold = 500000# reclassify the distance to 1 and NAdx <- calc(d, function(x) ifelse(x < distanceThreshold, 1, NA))# get all the patch IDs that are inside the distances thresholdpatches <- unique(dx * clmp)# get the complete patches, including areas outside of distance thresholdr.rasterThresh01TP.Clip <- calc(clmp, function(x) ifelse(x %in% patches, 1, 0))# replace 0 with NA in 1 percent training presence raster -- for writingr.rasterThresh01TP.Clip[r.rasterThresh01TP.Clip[]==0] <- NAprint("Finished evaluation")elapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))# write the best (1 percent training presence) thresholded raster to the hard diskprojection(r.rasterThresh01TP.Clip) <- myprjprint("Writing binary model to disk")binaryModel <- paste(maxTifDir, species, ".tif",
sep="")rf <- writeRaster(r.rasterThresh01TP.Clip, filename=binaryModel, format="GTiff", datatype="INT1U", overwrite=TRUE)elapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))# write shapefile to disk (LAEA projections)myShpFile <- paste0(species, ".shp")print("Check that gdal_polygonize will run properly on maverick")print(paste0(maxShpDir, myShpFile))myCommand <- paste("gdal_polygonize.py -f 'ESRI Shapefile' ", binaryModel, " ", maxShpDir, myShpFile, sep="")print(myCommand)mySysCmd <- invisible(system(myCommand))if(class(mySysCmd) == "try-error") {  shpWrite <- "No"} else {  shpWrite <- "Yes"  # write projection file  myShapePrj <- paste(maxShpDir, myShpFile, ".prj", sep='')  cat(showWKT(myprj, file="myShapePrj"))}elapsedTime <- proc.time() - startdateprint(paste("elapsedTime: ", elapsedTime[3]))#write jpg to disk myJpgFile <- paste0(species, ".jpg")print("Check that plant-o-matic will read the LAEA jpgs")print(paste0(maxJpgDir, myJpgFile))makeJpgCm
d <- paste("gdal_translate -of JPEG -scale -co worldfile=yes ", binaryModel, " ", maxJpgDir, myJpgFile, sep="")print(makeJpgCmd)SysJpgCmd <- invisible(system(makeJpgCmd))if (class(makeJpgCmd) == "try-error") {   jpgWrite <-"No"} else {   jpgWrite <- "Yes"}elapsedTIme <- proc.time() - startdateprint(paste("elapsedTime: ", elapsedTime[3]))#thresholded model at 1% training presenceprint("Counting the cells in the 1% TP")r.rasterThresh01TP.count <- freq(r.rasterThresh01TP, value=TRUE, useNA="no")cellsize01TP <- res(r.rasterThresh01TP)[1] * res(r.rasterThresh01TP)[2]r.rasterThresh01TP.area <- r.rasterThresh01TP.count * cellsize01TPprint(paste0("Cellsize01TP: ", cellsize01TP))#print(paste0("rasterThresh01TP.area :",r.rasterThresh01TP.area))r.rasterThresh01TP.Clip.count <- freq(r.rasterThresh01TP.Clip, value=1, useNA="no")cellsize01TP <- res(r.rasterThresh01TP.Clip)[1] * res(r.rasterThresh01TP.Clip)[2]r.rasterThresh01TP.Clip.area <- r.rasterThresh01TP.Clip.count * cellsize01TP#get the ending
time for this operationelapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))# record the model run results to the statistics filemySpecies <- paste(species) # reformat the species name for CSV outputnotes <- "Ok"# CM: just commented out the things we don't need for nowm[1,] <- c(mySpecies,# 	maxentModelType,# 	cellsize01TP,# 	r.rasterThresh01TP.area,# 	r.rasterThresh01TP.Clip.area,# 	r.tps,# 	r.fps,# 	r.tns,# 	r.fns,# 	r.sensitivity,# 	r.specificity,# 	r.totaccur,# 	r.auc,# 	r.corr,# 	r.thresh01TP,	shpWrite,  jpgWrite,	elapsedTime[3],	notes)# write the maxent statistics to CSV filfilename <- paste(statdir, "/", species, "_", maxentModelType, ".csv", sep="")print(paste0("Writing statisics to ", filename))write.csv(m, file=filename)filename <- paste(threshstatdir, "/", species, "_", maxentModelType, "_Thresholds.csv", sep="")print(paste0("Writing thresholds to ", filename))write.csv(r.thresholds, file=filename)# finishedprint(paste("Finished
MAXENT model for", species))#} else {#print(paste("Skipping", basename(speciesCSV), "- model already run."))#}#end id already exists}#end function#-------------------#p------ END --------#-------------------#-------------------#------ TEST -------#-------------------#uncomment to test# basedir <- "/home/02897/npcasler/test"# speciesCSV <- "/home/02897/npcasler/test/SpeciesCSVs/5Points/Abies_amabilis.csv"# outputdir <- "/home/02897/npcasler/test/output"# useCustomJunkPath <- FALSE# # myResult <- computeSDM_BioclimSpatial(speciesCSV, basedir, outputdir, useCustomJunkPath)# if(class(myResult) == "try-error") {# 	print("Error running CreateSDM_Bioclim function")# } else {# 	print("Completed processing")# }
startdate=proc.time()print(paste0('Process started at ', proc.time()))# naming is legacy of models compared in bien2maxentModelType <- "Maxent_BioclimSpatial"# get the path of script executionworkingdir <- basedir# set the path to the environmental dataenvdir <- paste(basedir, "/Env", sep="")bgdir <- paste(basedir, "/bg", sep="")maxdirname <- maxentModelType# CM: we don't need this for now since we can just read in the maxentResults file# create a matrix to hold the model resultsm <- matrix(nrow=0,ncol=5,byrow=TRUE)colnames(m) <- c(	"species",# 	"maxentModelType",# 	"cellSize",# #	"cellAreaFixed",# #	"cellAreaMaxSS",# #	"cellAreaBalSS",# #	"cellAreaMaxKappa",# #	"cellAreaMTP",# 	"cellArea01TP",# 	"cellArea01TPClip",# #	"cellArea05TP",# #	"cellArea10TP",# 	"truePositives",# 	"falsePositives",# 	"trueNegatives",# 	"falseNegatives",# 	"Sensitivity",# 	"Specificity",# 	"totalAccuracy",# 	"aucScore",# 	"correlationScore",# #	"maxKappaScore",# #	"thresholdFixed",# #	"thr
esholdMaxSS",# #	"thresholdBalSS",# #	"thresholdMaxKappa",# #	"thresholdMTP",# 	"threshold01TP",# #	"threshold05TP",# #	"threshold10TP",	"shapefileWritten",  "jpgWritten",	"elapsedTime",	"notes")
m <- transform(m, species = as.character(species),	# maxentModelType = as.character(maxentModelType),	# 	cellSize = as.numeric(cellSize),# #	cellAreaFixed = as.numeric(cellAreaFixed),# #	cellAreaMaxSS = as.numeric(cellAreaMaxSS),# #	cellAreaBalSS = as.numeric(cellAreaBalSS),# #	cellAreaMaxKappa = as.numeric(cellAreaMaxKappa),# #	cellAreaMTP = as.numeric(cellAreaMTP),# 	cellArea01TP = as.numeric(cellArea01TP),# 	cellArea01TPClip = as.numeric(cellArea01TPClip),# #	cellArea05TP = as.numeric(cellArea05TP),# #	cellArea10TP = as.numeric(cellArea10TP),# 	truePositives = as.numeric(truePositives),# 	falsePositives = as.numeric(falsePositives),# 	trueNegatives = as.numeric(trueNegatives),# 	falseNegatives = as.numeric(falseNegatives),# 	Sensitivity = as.numeric(Sensitivity),# 	Specificity = as.numeric(Specificity),# 	totalAccuracy = as.numeric(totalAccuracy),# 	aucScore = as.numeric(aucScore),# 	correlationScore = as.numeric(correlationScore),# #	maxKappaScore = as.numeric(maxKappaScore),# #	th
resholdFixed = as.numeric(thresholdFixed),# #	thresholdMaxSS = as.numeric(thresholdMaxSS),# #	thresholdBalSS = as.numeric(thresholdBalSS),# #	thresholdMaxKappa = as.numeric(thresholdMaxKappa),# #	thresholdMTP = as.numeric(thresholdMTP),# 	threshold01TP = as.numeric(threshold01TP),# #	threshold05TP = as.numeric(threshold05TP),# #	threshold10TP = as.numeric(threshold10TP),	elapsedTime = as.character(elapsedTime),	shapefileWritten = as.character(shapefileWritten),        jpgWritten = as.character(jpgWritten),	notes = as.character(notes))
myprj = "+proj=laea +lat_0=15 +lon_0=-80 +x_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs +towgs=0,0,0"# check if the species csv file existsif (file.exists(speciesCSV) == FALSE) {	errmsg <- paste("Input species CSV file", speciesCSV, "does not exist.")	stop(errmsg)}# check if the environmental raster directory existsif (file.exists(envdir) == FALSE) {	errmsg <- paste("Environmental layers directory", envdir, "does not exist.")	stop(errmsg)}# check to see if the base output directory existsif (file.exists(outputdir) == FALSE) {	errmsg <- paste("Output directory", outputdir, "does not exist.")	stop(errmsg)}# Check for output file directories, create them if they do not existmaxdir <- paste(outputdir, "/Maxent/", sep='')if (file.exists(maxdir) == FALSE) {dir.create(maxdir)}maxdir <- paste(outputdir, "/Maxent/", maxdirname, sep="")if (file.exists(maxdir) == FALSE) {dir.create(maxdir)}
maxTmpDir <- paste(maxdir, "/tmp/", sep="")if (file.exists(maxTmpDir) == FALSE) { dir.create(maxTmpDir)}#set the path to the Geotiff folder to hold the binary tiffsmaxTifDir <- paste(maxdir, "/GeoTiff/", sep='')if (file.exists(maxTifDir) == FALSE) {dir.create(maxTifDir)}#set the path to the shapefile folder to hold the binary shapefilesmaxShpDir <- paste(maxdir, "/Shapefile/", sep='')if (file.exists(maxShpDir) == FALSE) {dir.create(maxShpDir)}#set the path to the jpg folder to hold tha jpgs for the plant-o-matic appmaxJpgDir <- paste(maxdir, "/Jpg/", sep='')if (file.exists(maxJpgDir) == FALSE) {dir.create(maxJpgDir)}# set the path to the output statistics folderstatdir <- paste(outputdir, "/Statistics", sep='')if (file.exists(statdir) == FALSE) {dir.create(statdir)}#set the path to the output thresholds folderthreshstatdir <- paste(statdir, "/Thresholds", sep="")if (file.exists(threshstatdir) == FALSE) {dir.create(threshstatdir)}# get the species name from the csvspecies=strsplit(basename
(speciesCSV), '.csv')print(paste("Reading species occurrence records in", basename(speciesCSV)))
inputCSV <- paste0(maxTmpDir, species, '.csv')copycmd <- paste0("cut -f2- -d ',' ",speciesCSV, " > ", inputCSV)print(copycmd)system(copycmd)elapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))
print(paste("Creating Maxent", maxentModelType, "Model for", species))#get the starting time for this operationelapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))	# CM: changed a few settings#			1. added maxent path	# 		2. removed random testpoints# 	system(paste0('java -mx4024m -jar ',# 		'/home/02897/npcasler/maxent.jar nowarnings noprefixes -a -z outputdirectory=',maxdir,# 		" samplesfile=", inputCSV,# 		" environmentallayers=",bgdir,'/bg_swd.csv',# 		' randomtestpoints=20 outputformat=raw writemess=FALSE',# 		' projectionlayers=', envdir, ' maximumbackground=30000'))# CM: remove random test points=20 (pending email discussion).# CM: it is probably easiest to just remove the unused predictors from the environmental directories layer (see email discussion) but you could manually omit all the predictors in the maxent call with -N predictor_name# CM: note that if we are really are only get the binary map and toss raw output, maxent can do this for us by set
ting applyThresholdRule='Fixed cumulative value 1' or some other relevant value#CM: this is the version we'll use if we do species swd
rr=read.csv(inputCSV)
rr
head(rr)
maxdir
inputCSV
bgdir
system(paste0('java -mx4024m -jar ',maxentdir,		' nowarnings noprefixes -a -z outputdirectory=',maxdir,		" samplesfile=", inputCSV,		" environmentallayers=",bgdir,'/bg_swd.csv',		' outputformat=raw writemess=FALSE',		' projectionlayers=', envdir, ' maximumbackground=30000 nothreshold'))
elapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))
print(paste("Finished MAXENT model for", species))print('Evaluating the Maxent Model')
r <- raster(paste0(maxdir,'/',species, '_Env.asc'))print(paste0('Loading environmental data from ', envdir))predictors <- stack(list.files(path=envdir, pattern='asc', full.names=TRUE))
tmp=read.csv(paste0(maxdir,species,'_samplePredictions.csv')
tmp=read.csv(paste0(maxdir,species,'_samplePredictions.csv'))
paste0(maxdir,species,'_samplePredictions.csv')
tmp=read.csv(paste0(maxdir,'/',species,'_samplePredictions.csv'))
head(tmp)
r.thresh01TP <- quantile(tmp[tmp$Test.or.Train=='train','Raw.prediction'],.01)
?quantile
tmp[tmp$Test.or.Train=='train','Raw.prediction']
tmp$Test.or.Train
tmp$Test.or.train
r.thresh01TP <- quantile(tmp[tmp$Test.or.train=='train','Raw.prediction'],.01)
r.thresh01TP
r.rasterThresh01TP <- (r >= r.thresh01TP)
clmp <- clump(r.rasterThresh01TP)
plot)r.rasterThresh01TP
plot(r.rasterThresh01TP)
clmp <- clump(r.rasterThresh01TP)# insteadof rasterizing polygons, you can use distance# or dustanceFromPonts, we haven't checked into which is faster <<-- CHECK INTO THIS#first need to get the points for the cellspoints <-xyFromCell(r, pts[,1])d <- distanceFromPoints(r, points)distanceThreshold = 500000# reclassify the distance to 1 and NAdx <- calc(d, function(x) ifelse(x < distanceThreshold, 1, NA))# get all the patch IDs that are inside the distances thresholdpatches <- unique(dx * clmp)# get the complete patches, including areas outside of distance thresholdr.rasterThresh01TP.Clip <- calc(clmp, function(x) ifelse(x %in% patches, 1, 0))
pts
pts <- read.csv(file=speciesCSV, header=TRUE)
points <-xyFromCell(r, pts[,1])d <- distanceFromPoints(r, points)distanceThreshold = 500000# reclassify the distance to 1 and NAdx <- calc(d, function(x) ifelse(x < distanceThreshold, 1, NA))
# get all the patch IDs that are inside the distances thresholdpatches <- unique(dx * clmp)# get the complete patches, including areas outside of distance thresholdr.rasterThresh01TP.Clip <- calc(clmp, function(x) ifelse(x %in% patches, 1, 0))# replace 0 with NA in 1 percent training presence raster -- for writingr.rasterThresh01TP.Clip[r.rasterThresh01TP.Clip[]==0] <- NAprint("Finished evaluation")elapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))# write the best (1 percent training presence) thresholded raster to the hard diskprojection(r.rasterThresh01TP.Clip) <- myprjprint("Writing binary model to disk")binaryModel <- paste(maxTifDir, species, ".tif", sep="")rf <- writeRaster(r.rasterThresh01TP.Clip, filename=binaryModel, format="GTiff", datatype="INT1U", overwrite=TRUE)elapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))# write shapefile to disk (LAEA projections)myShpFile <- paste0(species, ".shp")print("Check that g
dal_polygonize will run properly on maverick")print(paste0(maxShpDir, myShpFile))myCommand <- paste("gdal_polygonize.py -f 'ESRI Shapefile' ", binaryModel, " ", maxShpDir, myShpFile, sep="")print(myCommand)mySysCmd <- invisible(system(myCommand))if(class(mySysCmd) == "try-error") {  shpWrite <- "No"} else {  shpWrite <- "Yes"  # write projection file  myShapePrj <- paste(maxShpDir, myShpFile, ".prj", sep='')  cat(showWKT(myprj, file="myShapePrj"))}elapsedTime <- proc.time() - startdateprint(paste("elapsedTime: ", elapsedTime[3]))
myJpgFile <- paste0(species, ".jpg")print("Check that plant-o-matic will read the LAEA jpgs")print(paste0(maxJpgDir, myJpgFile))makeJpgCmd <- paste("gdal_translate -of JPEG -scale -co worldfile=yes ", binaryModel, " ", maxJpgDir, myJpgFile, sep="")print(makeJpgCmd)SysJpgCmd <- invisible(system(makeJpgCmd))if (class(makeJpgCmd) == "try-error") {   jpgWrite <-"No"} else {   jpgWrite <- "Yes"}elapsedTIme <- proc.time() - startdateprint(paste("elapsedTime: ", elapsedTime[3]))
print("Counting the cells in the 1% TP")r.rasterThresh01TP.count <- freq(r.rasterThresh01TP, value=TRUE, useNA="no")cellsize01TP <- res(r.rasterThresh01TP)[1] * res(r.rasterThresh01TP)[2]r.rasterThresh01TP.area <- r.rasterThresh01TP.count * cellsize01TPprint(paste0("Cellsize01TP: ", cellsize01TP))#print(paste0("rasterThresh01TP.area :",r.rasterThresh01TP.area))r.rasterThresh01TP.Clip.count <- freq(r.rasterThresh01TP.Clip, value=1, useNA="no")cellsize01TP <- res(r.rasterThresh01TP.Clip)[1] * res(r.rasterThresh01TP.Clip)[2]r.rasterThresh01TP.Clip.area <- r.rasterThresh01TP.Clip.count * cellsize01TP#get the ending time for this operationelapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))# record the model run results to the statistics filemySpecies <- paste(species) # reformat the species name for CSV outputnotes <- "Ok"# CM: just commented out the things we don't need for nowm[1,] <- c(mySpecies,# 	maxentModelType,# 	cellsize01TP,# 	r.rasterThresh01TP.area
,# 	r.rasterThresh01TP.Clip.area,# 	r.tps,# 	r.fps,# 	r.tns,# 	r.fns,# 	r.sensitivity,# 	r.specificity,# 	r.totaccur,# 	r.auc,# 	r.corr,# 	r.thresh01TP,	shpWrite,  jpgWrite,	elapsedTime[3],	notes)# write the maxent statistics to CSV filfilename <- paste(statdir, "/", species, "_", maxentModelType, ".csv", sep="")print(paste0("Writing statisics to ", filename))write.csv(m, file=filename)filename <- paste(threshstatdir, "/", species, "_", maxentModelType, "_Thresholds.csv", sep="")print(paste0("Writing thresholds to ", filename))write.csv(r.thresholds, file=filename)# finishedprint(paste("Finished MAXENT model for", species))
filename
#subCreateSDM_BioclimSpatial.r## This version models with bioclim and spatial layers.### Subroutine that computes a maxent model for a given species occurrence file.# Thiis script is called from other R scripts. Saves a raster version of the # raw maxent model.## By Nathan Casler# Adapted from subCreateSDM_BioclimSpatial.r by John C Donoghue II# Last updated: August 19, 2014## Requires 4 inputs# <path and filename of input file># <base path of working directory># <base path of output directory># <using custom junk path TRUE|FALSE># <base path of maxent.jar file>##TODO: set the custom junk path to write out samples file## CHECK INTO HOW TO HANDLE SAMPLES FILES## RECREATE THE BACKGROUND FILE## RESET THE pts.train and pts.test for Maxent and evaluation##Add code for gdal_polygonize#------------------#------ START -----#------------------#IF TESTINGoptions(java.parameters = "-Xmx4g")library(rgdal)library(sp)library(raster)library(dismo)library(igraph)#------------------
---- FUNCTION----#------------------# CM: added maxent path (maxentdir) so others can use on their systemscomputeSDM_BioclimSpatial <- function(speciesCSV, basedir, outputdir, customJunkPath, maxentdir) {# Get the start time of the functionstartdate=proc.time()print(paste0('Process started at ', proc.time()))# naming is legacy of models compared in bien2maxentModelType <- "Maxent_BioclimSpatial"# get the path of script executionworkingdir <- basedir# set the path to the environmental dataenvdir <- paste(basedir, "/Env", sep="")bgdir <- paste(basedir, "/bg", sep="")maxdirname <- maxentModelType# CM: we don't need this for now since we can just read in the maxentResults file# create a matrix to hold the model resultsm <- matrix(nrow=0,ncol=5,byrow=TRUE)colnames(m) <- c(	"species",# 	"maxentModelType",# 	"cellSize",# #	"cellAreaFixed",# #	"cellAreaMaxSS",# #	"cellAreaBalSS",# #	"cellAreaMaxKappa",# #	"cellAreaMTP",# 	"cellArea01TP",# 	"cellArea01TPClip",# #	"cellArea05TP",#
 #	"cellArea10TP",# 	"truePositives",# 	"falsePositives",# 	"trueNegatives",# 	"falseNegatives",# 	"Sensitivity",# 	"Specificity",# 	"totalAccuracy",# 	"aucScore",# 	"correlationScore",# #	"maxKappaScore",# #	"thresholdFixed",# #	"thresholdMaxSS",# #	"thresholdBalSS",# #	"thresholdMaxKappa",# #	"thresholdMTP",# 	"threshold01TP",# #	"threshold05TP",# #	"threshold10TP",	"shapefileWritten",  "jpgWritten",	"elapsedTime",	"notes")m <- transform(m, species = as.character(species),	# maxentModelType = as.character(maxentModelType),	# 	cellSize = as.numeric(cellSize),# #	cellAreaFixed = as.numeric(cellAreaFixed),# #	cellAreaMaxSS = as.numeric(cellAreaMaxSS),# #	cellAreaBalSS = as.numeric(cellAreaBalSS),# #	cellAreaMaxKappa = as.numeric(cellAreaMaxKappa),# #	cellAreaMTP = as.numeric(cellAreaMTP),# 	cellArea01TP = as.numeric(cellArea01TP),# 	cellArea01TPClip = as.numeric(cellArea01TPClip),# #	cellArea05TP = as.numeric(cellArea05TP),# #	cellArea10TP = as.numeric(cellArea10TP),# 	tru
ePositives = as.numeric(truePositives),# 	falsePositives = as.numeric(falsePositives),# 	trueNegatives = as.numeric(trueNegatives),# 	falseNegatives = as.numeric(falseNegatives),# 	Sensitivity = as.numeric(Sensitivity),# 	Specificity = as.numeric(Specificity),# 	totalAccuracy = as.numeric(totalAccuracy),# 	aucScore = as.numeric(aucScore),# 	correlationScore = as.numeric(correlationScore),# #	maxKappaScore = as.numeric(maxKappaScore),# #	thresholdFixed = as.numeric(thresholdFixed),# #	thresholdMaxSS = as.numeric(thresholdMaxSS),# #	thresholdBalSS = as.numeric(thresholdBalSS),# #	thresholdMaxKappa = as.numeric(thresholdMaxKappa),# #	thresholdMTP = as.numeric(thresholdMTP),# 	threshold01TP = as.numeric(threshold01TP),# #	threshold05TP = as.numeric(threshold05TP),# #	threshold10TP = as.numeric(threshold10TP),	elapsedTime = as.character(elapsedTime),	shapefileWritten = as.character(shapefileWritten),        jpgWritten = as.character(jpgWritten),	notes = as.character(notes))#
# Set the projection definitionmyprj = "+proj=laea +lat_0=15 +lon_0=-80 +x_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs +towgs=0,0,0"# check if the species csv file existsif (file.exists(speciesCSV) == FALSE) {	errmsg <- paste("Input species CSV file", speciesCSV, "does not exist.")	stop(errmsg)}# check if the environmental raster directory existsif (file.exists(envdir) == FALSE) {	errmsg <- paste("Environmental layers directory", envdir, "does not exist.")	stop(errmsg)}# check to see if the base output directory existsif (file.exists(outputdir) == FALSE) {	errmsg <- paste("Output directory", outputdir, "does not exist.")	stop(errmsg)}# Check for output file directories, create them if they do not existmaxdir <- paste(outputdir, "/Maxent/", sep='')if (file.exists(maxdir) == FALSE) {dir.create(maxdir)}maxdir <- paste(outputdir, "/Maxent/", maxdirname, sep="")if (file.exists(maxdir) == FALSE) {dir.create(maxdir)}#set the path to the tmp folder to hold intermediate outputsmaxTmpDi
r <- paste(maxdir, "/tmp/", sep="")if (file.exists(maxTmpDir) == FALSE) { dir.create(maxTmpDir)}#set the path to the Geotiff folder to hold the binary tiffsmaxTifDir <- paste(maxdir, "/GeoTiff/", sep='')if (file.exists(maxTifDir) == FALSE) {dir.create(maxTifDir)}#set the path to the shapefile folder to hold the binary shapefilesmaxShpDir <- paste(maxdir, "/Shapefile/", sep='')if (file.exists(maxShpDir) == FALSE) {dir.create(maxShpDir)}#set the path to the jpg folder to hold tha jpgs for the plant-o-matic appmaxJpgDir <- paste(maxdir, "/Jpg/", sep='')if (file.exists(maxJpgDir) == FALSE) {dir.create(maxJpgDir)}# set the path to the output statistics folderstatdir <- paste(outputdir, "/Statistics", sep='')if (file.exists(statdir) == FALSE) {dir.create(statdir)}#set the path to the output thresholds folderthreshstatdir <- paste(statdir, "/Thresholds", sep="")if (file.exists(threshstatdir) == FALSE) {dir.create(threshstatdir)}# get the species name from the csvspecies=strsplit(basename(species
CSV), '.csv')print(paste("Reading species occurrence records in", basename(speciesCSV)))# Kfold partitioning - withold 20% of the sample for testing # CM: we don't need to ask maxent to do the evaluation# CM: NOT NEEDED, AS FAR AS I CAN TELL pts <- read.csv(file=speciesCSV, header=TRUE) # CM: elapsedTime <- proc.time() - startdate# CM: print(paste0("elapsedTime: ", elapsedTime[3]))# CM: # fold <- kfold(pts, k=5)# CM: # pts.test <- pts[fold == 1, ]# CM: # pts.train <- pts[fold != 1, ]# CM: print("Species points class is")# CM: print(class(pts))#check to see if the model has already been run#filename <- paste(maxdir, '/', species, '_', maxentModelType, ".csv", sep="")#if (file.exists(filename) == FALSE)  {inputCSV <- paste0(maxTmpDir, species, '.csv')copycmd <- paste0("cut -f2- -d ',' ",speciesCSV, " > ", inputCSV)print(copycmd)system(copycmd)elapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))#
print(paste("Creating Maxent", maxentModelType, "Model for", species))#get the starting time for this operationelapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))	# CM: changed a few settings#			1. added maxent path	# 		2. removed random testpoints#	 		3. remember to make the species CSVs and backgroundswd with just the new set of predictors#  CM: old version below#  CM: 	system(paste0('java -mx4024m -jar ',#  CM:		'/home/02897/npcasler/maxent.jar nowarnings noprefixes -a -z  #	 CM: outputdirectory=',maxdir,#  CM:		" samplesfile=", inputCSV,#  CM:		" environmentallayers=",bgdir,'/bg_swd.csv',#  CM:		' randomtestpoints=20 outputformat=raw writemess=FALSE',#  CM: 		' projectionlayers=', envdir, ' maximumbackground=30000'))#CM:  note that maxent doesn't see to like the predictor names in the the specieCSV file. e.g. i get the following for all predictors and not sure what th issue is, but the models seems to run fine:	# Warning: Unused field bio_12_p in Abi
es_grandis.csv	system(paste0('java -mx4024m -jar ',maxentdir,		' nowarnings noprefixes -a -z outputdirectory=',maxdir,		" samplesfile=", inputCSV,		" environmentallayers=",bgdir,'/bg_swd.csv',		' outputformat=raw writemess=FALSE',		' projectionlayers=', envdir, ' maximumbackground=30000 nothreshold'))elapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))#
print(paste("Finished MAXENT model for", species))print('Evaluating the Maxent Model')# CM: we don't need these until we do some real evaluation# CM: # Load the background data for sampling# CM: bg <- read.csv(file=paste0(bgdir, '/bg_swd.csv'))# CM: # Sample background data to 10% of total(3000)# CM: bg1 <- bg[sample(nrow(bg), 3000), ]#
#retrive maxent model outputr <- raster(paste0(maxdir,'/',species, '_Env.asc'))# CM: we don't seem to need this if we're not doing evaluation# CM: print(paste0('Loading environmental data from ', envdir))# CM: predictors <- stack(list.files(path=envdir, pattern='asc', full.names=TRUE))# CM: I don't see the point in these evaluation statistics. maxent already reports some of them, so just read them in from the maxentResults.csv associated with each run. evenually, when i've developed a useful way to do this, we'll do some evaluation, but that's a ways off.# CM: it would be great to just record the entire maxetnResults file. but if that's an issue, for this evaluation stuff i'd record the columns named Regularized training gain,	Unregularized training gain, Training AUC, #training samples, entropy# print('Environmental data loaded evaluating...')# # Extract the maxent values for a test subset of the presence points# pts.test <- extract(r, pts.test[,1])# # # print("Pts.test loaded")# #Extract t
he maxent values for the background samples# bg.test <- extract(r, bg1[,1])# print("bg.test loaded")# # #evaluate the presence and absence points# e1 = evaluate(p=pts.test, a=bg.test)# elapsedTime <- proc.time() - startdate# print(paste0("elapsedTime: ", elapsedTime[3]))# print(e1)# # get the number of presences# r.numpres <- e1@np# # # get the number of absences# r.numabs <- e1@na# # # get the AUC# r.auc <- e1@auc# # # get the correlation# r.corr <- e1@cor# # # get the kappa score - maximum kappa# #r.kappa <- which.max(e1.kappa)# # # get the true/false positive/negative totals from the confusion tables# r.tps <- sum(e1@confusion[,1])# r.fps <- sum(e1@confusion[,2])# r.tns <- sum(e1@confusion[,3])# r.fns <- sum(e1@confusion[,4])# # # get the total points# totpts <- r.tps + r.fps + r.tns + r.fns# # # get the sensitivity# r.sensitivity <- r.tps / (r.tps + r.fns)# # # get the specificity# r.specificity <- r.fps / (r.fps + r.tns)# # # get the overall accuracy (correct/tota
l)# r.totaccur <- (r.tps + r.tns) / totpts# CM: if we wanted to use a different trheshold rule we can just get these from the maxentResults.csv file, and avoid all the things that depend on evaluate. but if we want 1% training quantile, we have to calucalate that ourselves. for now, we'll calculate our own 1% training quantile threshold# get all the thresholds # r.thresholds <- e1@t# get the 01% training presence threshold# CM: read in the prediction file and calculate.tmp=read.csv(paste0(maxdir,'/',species,'_samplePredictions.csv'))r.thresh01TP <- quantile(tmp[tmp$Test.or.train=='train','Raw.prediction'],.01)# CM: not needed unless we calculate stats ourselves: r.thresh01TP <- quantile(e1@presence, 0.01)# get a raster of the cells that equal or exceed the threshold valuer.rasterThresh01TP <- (r >= r.thresh01TP)# CM: i'm not messing with any of this spatial stuff### run the advanced clipping method on the thresholded raster #### get patches in the raster layerclmp <- clump(r.rasterThresh0
1TP)# insteadof rasterizing polygons, you can use distance# or dustanceFromPonts, we haven't checked into which is faster <<-- CHECK INTO THIS#first need to get the points for the cellspoints <-xyFromCell(r, pts[,1])d <- distanceFromPoints(r, points)distanceThreshold = 500000# reclassify the distance to 1 and NAdx <- calc(d, function(x) ifelse(x < distanceThreshold, 1, NA))# get all the patch IDs that are inside the distances thresholdpatches <- unique(dx * clmp)# get the complete patches, including areas outside of distance thresholdr.rasterThresh01TP.Clip <- calc(clmp, function(x) ifelse(x %in% patches, 1, 0))# replace 0 with NA in 1 percent training presence raster -- for writingr.rasterThresh01TP.Clip[r.rasterThresh01TP.Clip[]==0] <- NAprint("Finished evaluation")elapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))# write the best (1 percent training presence) thresholded raster to the hard diskprojection(r.rasterThresh01TP.Clip) <- myprjprint("Wr
iting binary model to disk")binaryModel <- paste(maxTifDir, species, ".tif", sep="")rf <- writeRaster(r.rasterThresh01TP.Clip, filename=binaryModel, format="GTiff", datatype="INT1U", overwrite=TRUE)elapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))# write shapefile to disk (LAEA projections)myShpFile <- paste0(species, ".shp")print("Check that gdal_polygonize will run properly on maverick")print(paste0(maxShpDir, myShpFile))myCommand <- paste("gdal_polygonize.py -f 'ESRI Shapefile' ", binaryModel, " ", maxShpDir, myShpFile, sep="")print(myCommand)mySysCmd <- invisible(system(myCommand))if(class(mySysCmd) == "try-error") {  shpWrite <- "No"} else {  shpWrite <- "Yes"  # write projection file  myShapePrj <- paste(maxShpDir, myShpFile, ".prj", sep='')  cat(showWKT(myprj, file="myShapePrj"))}elapsedTime <- proc.time() - startdateprint(paste("elapsedTime: ", elapsedTime[3]))#write jpg to disk myJpgFile <- paste0(species, ".jpg")print("Check that plant-o-
matic will read the LAEA jpgs")print(paste0(maxJpgDir, myJpgFile))makeJpgCmd <- paste("gdal_translate -of JPEG -scale -co worldfile=yes ", binaryModel, " ", maxJpgDir, myJpgFile, sep="")print(makeJpgCmd)SysJpgCmd <- invisible(system(makeJpgCmd))if (class(makeJpgCmd) == "try-error") {   jpgWrite <-"No"} else {   jpgWrite <- "Yes"}elapsedTIme <- proc.time() - startdateprint(paste("elapsedTime: ", elapsedTime[3]))#thresholded model at 1% training presenceprint("Counting the cells in the 1% TP")r.rasterThresh01TP.count <- freq(r.rasterThresh01TP, value=TRUE, useNA="no")cellsize01TP <- res(r.rasterThresh01TP)[1] * res(r.rasterThresh01TP)[2]r.rasterThresh01TP.area <- r.rasterThresh01TP.count * cellsize01TPprint(paste0("Cellsize01TP: ", cellsize01TP))#print(paste0("rasterThresh01TP.area :",r.rasterThresh01TP.area))r.rasterThresh01TP.Clip.count <- freq(r.rasterThresh01TP.Clip, value=1, useNA="no")cellsize01TP <- res(r.rasterThresh01TP.Clip)[1] * res(r.rasterThresh01TP.Clip)[2]r.rasterThresh01T
P.Clip.area <- r.rasterThresh01TP.Clip.count * cellsize01TP#get the ending time for this operationelapsedTime <- proc.time() - startdateprint(paste0("elapsedTime: ", elapsedTime[3]))# record the model run results to the statistics filemySpecies <- paste(species) # reformat the species name for CSV outputnotes <- "Ok"# CM: just commented out the things we don't need for nowm[1,] <- c(mySpecies,# 	maxentModelType,# 	cellsize01TP,# 	r.rasterThresh01TP.area,# 	r.rasterThresh01TP.Clip.area,# 	r.tps,# 	r.fps,# 	r.tns,# 	r.fns,# 	r.sensitivity,# 	r.specificity,# 	r.totaccur,# 	r.auc,# 	r.corr,# 	r.thresh01TP,	shpWrite,  jpgWrite,	elapsedTime[3],	notes)# write the maxent statistics to CSV filfilename <- paste(statdir, "/", species, "_", maxentModelType, ".csv", sep="")print(paste0("Writing statisics to ", filename))write.csv(m, file=filename)# CM: I don't think we use this for anything# filename <- paste(threshstatdir, "/", species, "_", maxentModelType, "_Thresholds.csv", sep=""
)# print(paste0("Writing thresholds to ", filename))# write.csv(r.thresholds, file=filename)# finishedprint(paste("Finished MAXENT model for", species))#} else {#print(paste("Skipping", basename(speciesCSV), "- model already run."))#}#end id already exists}#end function#-------------------#p------ END --------#-------------------#-------------------#------ TEST -------#-------------------#uncomment to test# basedir <- "/home/02897/npcasler/test"# speciesCSV <- "/home/02897/npcasler/test/SpeciesCSVs/5Points/Abies_amabilis.csv"# outputdir <- "/home/02897/npcasler/test/output"# useCustomJunkPath <- FALSE# # myResult <- computeSDM_BioclimSpatial(speciesCSV, basedir, outputdir, useCustomJunkPath)# if(class(myResult) == "try-error") {# 	print("Error running CreateSDM_Bioclim function")# } else {# 	print("Completed processing")# }
basedir <- "/Users/ctg/Documents/BIEN_models/test_dir"speciesCSV <- "/Users/ctg/Documents/BIEN_models/test_dir/SpeciesCSVs/Abies_grandis.csv"outputdir <- "/Users/ctg/Documents/BIEN_models/test_dir/out"useCustomJunkPath <- TRUEmaxentdir='/Users/ctg/Dropbox/MaxEnt/Program/maxent.jar'
myResult <- computeSDM_BioclimSpatial(speciesCSV, basedir, outputdir, useCustomJunkPath,maxentdir)
if(class(myResult) == "try-error") {	print("Error running CreateSDM_Bioclim function")} else {	print("Completed processing")}
basedir='/Users/ctg/Documents/BIEN_models/BIENRangeModelingTACC'#==========================================================================#==========================================================================#==========================================================================#== General summaries not specific to an experiment#==========================================================================#==========================================================================#==========================================================================envbiodir <- paste0(basedir, "/EnvironmentalRasters/Clipped/NewWorld/woGreenland/Bioclim/ASC")envspadir <- paste0(basedir, "/EnvironmentalRasters/Clipped/NewWorld/woGreenland/SpatialFilters/ASC")biofiles <- list.files(path=envbiodir, pattern='asc', full.names=TRUE)spafiles <- list.files(path=envspadir, pattern='asc', full.names=TRUE)predictors <- stack(c(biofiles, spafiles))p=values(predictors[[1:19]])colnames(p)=paste0('bio_',c(1,10:19,
2:9),'_p')land=complete.cases(p)p=p[land,]toss.name=c(c('bio_10_p','bio_11_p','bio_3_p','bio_4_p','bio_5_p','bio_6_p','bio_7_p','bio_8_p','bio_9_p'),c('bio_13_p','bio_14_p','bio_16_p','bio_18_p','bio_19_p'),c('bio_17_p'))toss.num=match(toss.name, colnames(p))(cc=cor(p[,-toss.num],use='complete'))
toss.name=c(c('bio_10_p','bio_11_p','bio_2_p','bio_3_p','bio_5_p','bio_7_p','bio_8_p','bio_9_p'),c('bio_13_p','bio_14_p','bio_16_p','bio_18_p','bio_19_p'))toss.num=match(toss.name, colnames(p))
(cc=cor(p[,-toss.num],use='complete'))
p$bio_18_p
p['bio_18_p']
p
p=values(predictors[[1:19]])
land=complete.cases(p)
p=p[land,]
p$new_bio=p$bio_18_p/(p$bio_18_p+p$bio_19_p)
str(p)
names(p)=paste0('bio_',c(1,10:19,2:9),'_p')
names(p)
class(p)
p=values(predictors[[1:19]])colnames(p)=paste0('bio_',c(1,10:19,2:9),'_p')land=complete.cases(p)p=p[land,]
p2=cbind(p,p[,10]/(p[,10]+p[,11]))
str(p2)
colnames(p2)
p=cbind(p,p[,10]/(p[,10]+p[,11]))
colnames(p)[20]='new_bio'
colnames(p)
oss.name=c(c('bio_10_p','bio_11_p','bio_2_p','bio_3_p','bio_5_p','bio_7_p','bio_8_p','bio_9_p'),c('bio_13_p','bio_14_p','bio_16_p','bio_18_p','bio_19_p'))toss.num=match(toss.name, colnames(p))(cc=cor(p[,-toss.num],use='complete'))
toss.name=c(c('bio_10_p','bio_11_p','bio_3_p','bio_4_p','bio_5_p','bio_6_p','bio_7_p','bio_8_p','bio_9_p'),c('bio_13_p','bio_14_p','bio_16_p','bio_18_p','bio_19_p'),c('bio_17_p'))toss.num=match(toss.name, colnames(p))(cc=cor(p[,-toss.num],use='complete'))
(cc=cor(p,use='complete'))
write.csv(cc=cor(p,use='complete'),file='/Users/ctg/Desktop/bioclim_correlations.csv')
write.csv(cor(p,use='complete'),file='/Users/ctg/Desktop/bioclim_correlations.csv')
write.csv(round(cor(p,use='complete'),2),file='/Users/ctg/Desktop/bioclim_correlations.csv')
50000/60
library(raster)library(fields)setwd('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/temp_sharing/Application 4 Higher Order Taxon Info')cols1=function(x,bias=1) { colorRampPalette(c('grey80','grey50','steelblue4','steelblue1','steelblue1','gold','red1','red3'),bias=bias)(x) }#############################################read data ############################################(load('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/temp_sharing/protea_model_performance.RData'))AUREP=FALSE # use this for the example that doesn't work (that 1st try)if(AUREP) { 	tmp1=stack('pr_white.asc', 'praurep.asc','praurep_with_bias.asc')	#pres.atlas=read.csv('praurep_protea_atlas_pnts.csv')	pres.atlas=read.csv('p_nana_precis_occur.csv')	#pres.atlas.genus=read.csv('prwhite_protea_atlas_pnts.csv')	pres.atlas.genus=read.csv('rose_protea_no_nana_occur.csv')}NANA=TRUEif(NANA) { 	tmp1=stack('pr_rose_prior.asc', 'p_nana_precis_naive.asc','p_nana_precis_naive_stdev.asc','p_nana_minxent_avg.asc','p_nana_minxent_stdev.asc')	pres.atlas=read.csv('p_nana_precis_occur.csv')	pres.atlas.genus=read.csv('rose_protea_no_nana_occur.csv')	pres.atlas.real=read.csv('p_nana_atlas_occur.csv')	#pres.atlas.genus=read.csv('rose_protea_no_nana_occur.csv')}#
values(tmp1)[,c(1,2,4)]=apply(values(tmp1)[,c(1,2,4)],2,function(x) {x/sum(x,na.rm=T)})	#make a uniform prior for plotting#values(tmp1[[1]])[!is.na(values(tmp1[[1]]))]=1/sum(!is.na(values(tmp1[[1]])))#values(tmp1)[values(tmp1)<1e-10]=1e-10coordinates(pres.atlas.genus)=c(2,3)coordinates(pres.atlas)=c(2,3)coordinates(pres.atlas.real)=c(2,3)
titles=c("Training Data","Testing Data",'Genus Prior','Maxent Prediction\n(Uniform Prior)','S.D. of \n Maxent Predictions', 'Minxent Prediction\n(Genus Prior)', 'S.D. of \n Minxent Predictions')par(mar=c(.2,.1,1.5,.1),mfrow=c(4,2),oma=c(0,1,0,.3))z.max=max(values(tmp1),na.rm=T)x.min=min(values(tmp1),na.rm=T)min.quant=0 # the quantile below which grey scale is used.breaks=c(-100,quantile(values(tmp1), seq(min.quant,1,length=100),na.rm=T))lab=letters[1:10]image(tmp1[[1]] ,col='grey70',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))points(pres.atlas.genus,col='red2',pch=19,cex=.5)points(pres.atlas,bg='steelblue3',pch=21,cex=.7)text(22.5,-32,titles[1],cex=1.8)text(18,-31.2,lab[1],cex=1.3)image(tmp1[[1]] ,col='grey70',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))#points(pres.atlas.genus,col='red2',pch=19,cex=.5)points(pres.atlas.real,bg='steelblue3',pch=21,cex=.7)text(22.5,-32,titles[2],cex=1.8)text(18,-31.2,lab[2],cex=1.3)  	#spacer#image(tmp1[[i]] ,col='white',xaxt='n', yaxt='n', bty='n',main='')#
for(i in 1:dim(tmp1)[3]){ image(tmp1[[i]] ,col=cols1(100,bias=.5),xaxt='n', yaxt='n', bty='n',main='',cex.main=1.5, zlim=c(0,z.max), breaks=breaks) text(22.5,-32,titles[i+2],cex=1.8) text(18,-31.2,lab[i+2],cex=1.3)	#legend if(i==1){	 image(tmp1[[2]] ,col='white',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))	 image.plot(tmp1[[2]],legend.only=TRUE,col=cols1(100,bias=.5),xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, legend.args=list(text="relative\noccurrence rate",cex=1.2),smallplot=c(.05,.95,.55,.65),zlim=range(log(breaks[-1]),na.rm=T),breaks=c(-100,log(breaks[-1])),horizontal=TRUE,axis.args=list( at=log(quantile(values(tmp1), c(.001,.3,.7,1),na.rm=T)), labels=sprintf("%.0e",quantile(values(tmp1), c(.001,.3,.7,1),na.rm=T)))) }}
abs.atlas=read.csv('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Temp_sharing/Application 4 Higher Order Taxon Info/prall_train.csv')
head(abs.atlas)
par(mar=c(.2,.1,1.5,.1),mfrow=c(4,2),oma=c(0,1,0,.3))z.max=max(values(tmp1),na.rm=T)x.min=min(values(tmp1),na.rm=T)min.quant=0 # the quantile below which grey scale is used.breaks=c(-100,quantile(values(tmp1), seq(min.quant,1,length=100),na.rm=T))lab=letters[1:10]image(tmp1[[1]] ,col='grey70',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))points(pres.atlas.genus,col='red2',pch=19,cex=.5)points(pres.atlas,bg='steelblue3',pch=21,cex=.7)text(22.5,-32,titles[1],cex=1.8)text(18,-31.2,lab[1],cex=1.3)image(tmp1[[1]] ,col='grey70',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))#points(pres.atlas.genus,col='red2',pch=19,cex=.5)points(abs.atlas,pch=19,cex=.5)points(pres.atlas.real,bg='steelblue3',pch=21,cex=.7)text(22.5,-32,titles[2],cex=1.8)text(18,-31.2,lab[2],cex=1.3)  	#spacer#image(tmp1[[i]] ,col='white',xaxt='n', yaxt='n', bty='n',main='')#
for(i in 1:dim(tmp1)[3]){ image(tmp1[[i]] ,col=cols1(100,bias=.5),xaxt='n', yaxt='n', bty='n',main='',cex.main=1.5, zlim=c(0,z.max), breaks=breaks) text(22.5,-32,titles[i+2],cex=1.8) text(18,-31.2,lab[i+2],cex=1.3)	#legend if(i==1){	 image(tmp1[[2]] ,col='white',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))	 image.plot(tmp1[[2]],legend.only=TRUE,col=cols1(100,bias=.5),xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, legend.args=list(text="relative\noccurrence rate",cex=1.2),smallplot=c(.05,.95,.55,.65),zlim=range(log(breaks[-1]),na.rm=T),breaks=c(-100,log(breaks[-1])),horizontal=TRUE,axis.args=list( at=log(quantile(values(tmp1), c(.001,.3,.7,1),na.rm=T)), labels=sprintf("%.0e",quantile(values(tmp1), c(.001,.3,.7,1),na.rm=T)))) }}
par(mar=c(.2,.1,1.5,.1),mfrow=c(4,2),oma=c(0,1,0,.3))z.max=max(values(tmp1),na.rm=T)x.min=min(values(tmp1),na.rm=T)min.quant=0 # the quantile below which grey scale is used.breaks=c(-100,quantile(values(tmp1), seq(min.quant,1,length=100),na.rm=T))lab=letters[1:10]image(tmp1[[1]] ,col='grey70',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))points(pres.atlas.genus,col='red2',pch=19,cex=.5)points(pres.atlas,bg='steelblue3',pch=21,cex=.7)text(22.5,-32,titles[1],cex=1.8)text(18,-31.2,lab[1],cex=1.3)
image(tmp1[[1]] ,col='grey70',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))#points(pres.atlas.genus,col='red2',pch=19,cex=.5)
coordinates(abs.atlas)=c(2,3)
pres.atlas
abs.atlas
points(abs.atlas,pch=19,cex=.5)
points(pres.atlas.real,bg='steelblue3',pch=21,cex=.7)
image(tmp1[[1]] ,col='grey70',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))#points(pres.atlas.genus,col='red2',pch=19,cex=.5)points(abs.atlas,pch=19,cex=.3,col='grey30')points(pres.atlas.real,bg='steelblue3',pch=21,cex=.7)text(22.5,-32,titles[2],cex=1.8)text(18,-31.2,lab[2],cex=1.3)
image(tmp1[[1]] ,col='grey70',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))#points(pres.atlas.genus,col='red2',pch=19,cex=.5)points(abs.atlas,pch=19,cex=.3,col='grey40')points(pres.atlas.real,bg='steelblue3',pch=21,cex=.7)text(22.5,-32,titles[2],cex=1.8)text(18,-31.2,lab[2],cex=1.3)
image(tmp1[[1]] ,col='grey70',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))#points(pres.atlas.genus,col='red2',pch=19,cex=.5)points(abs.atlas,pch=19,cex=.3,col='grey45')points(pres.atlas.real,bg='steelblue3',pch=21,cex=.7)text(22.5,-32,titles[2],cex=1.8)text(18,-31.2,lab[2],cex=1.3)
image(tmp1[[1]] ,col='grey70',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))#points(pres.atlas.genus,col='red2',pch=19,cex=.5)points(abs.atlas,pch=19,cex=.2,col='grey45')points(pres.atlas.real,bg='steelblue3',pch=21,cex=.7)text(22.5,-32,titles[2],cex=1.8)text(18,-31.2,lab[2],cex=1.3)
if(AUREP) pdf('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_predictions_AUREP.pdf',h=6,w=5)if(NANA) pdf('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_predictions_NANA.pdf',h=6,w=5)titles=c("Training Data","Testing Data",'Genus Prior','Maxent Prediction\n(Uniform Prior)','S.D. of \n Maxent Predictions', 'Minxent Prediction\n(Genus Prior)', 'S.D. of \n Minxent Predictions')par(mar=c(.2,.1,1.5,.1),mfrow=c(4,2),oma=c(0,1,0,.3))z.max=max(values(tmp1),na.rm=T)x.min=min(values(tmp1),na.rm=T)min.quant=0 # the quantile below which grey scale is used.breaks=c(-100,quantile(values(tmp1), seq(min.quant,1,length=100),na.rm=T))lab=letters[1:10]image(tmp1[[1]] ,col='grey70',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))points(pres.atlas.genus,col='red2',pch=19,cex=.5)points(pres.atlas,bg='steelblue3',pch=21,cex=.7)text(22.5,-32,titles[1],cex=1.8)text(18,-31.2,lab[1],cex=1.3)image(tmp1[[1]] ,col='grey70',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))#points(pres.atlas.genus,col='red2',pch=19,cex=.5)points(abs.atlas,pch=19,cex=.2,col='grey45')points(pres.atlas.real,bg='steelblue3',pch=21,cex=.7)text(22.5,-32,titles[2],cex=1.8)text(18,-31.2,lab[2],cex=1.3)  	#spacer#image(tmp1[[i]] ,col='white',xaxt='n', yaxt='n', bty='n',main='')#
for(i in 1:dim(tmp1)[3]){ image(tmp1[[i]] ,col=cols1(100,bias=.5),xaxt='n', yaxt='n', bty='n',main='',cex.main=1.5, zlim=c(0,z.max), breaks=breaks) text(22.5,-32,titles[i+2],cex=1.8) text(18,-31.2,lab[i+2],cex=1.3)	#legend if(i==1){	 image(tmp1[[2]] ,col='white',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))	 image.plot(tmp1[[2]],legend.only=TRUE,col=cols1(100,bias=.5),xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, legend.args=list(text="relative\noccurrence rate",cex=1.2),smallplot=c(.05,.95,.55,.65),zlim=range(log(breaks[-1]),na.rm=T),breaks=c(-100,log(breaks[-1])),horizontal=TRUE,axis.args=list( at=log(quantile(values(tmp1), c(.001,.3,.7,1),na.rm=T)), labels=sprintf("%.0e",quantile(values(tmp1), c(.001,.3,.7,1),na.rm=T)))) }}dev.off()if(AUREP) system('open /Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_predictions_AUREP.pdf')if(NANA) system('open /Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_predictions_NANA.pdf')
if(AUREP) pdf('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_predictions_AUREP.pdf',h=6,w=5)if(NANA) pdf('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_predictions_NANA.pdf',h=6,w=5)titles=c("Training Data","Testing Data",'Taxonomic Prior','Maxent Prediction\n(Uniform Prior)','S.D. of \n Maxent Predictions', 'Minxent Prediction\n(Genus Prior)', 'S.D. of \n Minxent Predictions')par(mar=c(.2,.1,1.5,.1),mfrow=c(4,2),oma=c(0,1,0,.3))z.max=max(values(tmp1),na.rm=T)x.min=min(values(tmp1),na.rm=T)min.quant=0 # the quantile below which grey scale is used.breaks=c(-100,quantile(values(tmp1), seq(min.quant,1,length=100),na.rm=T))lab=letters[1:10]image(tmp1[[1]] ,col='grey70',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))points(pres.atlas.genus,col='red2',pch=19,cex=.5)points(pres.atlas,bg='steelblue3',pch=21,cex=.7)text(22.5,-32,titles[1],cex=1.8)text(18,-31.2,lab[1],cex=1.3)image(tmp1[[1]] ,col='grey70',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))#points(pres.atlas.genus,col='red2',pch=19,cex=.5)points(abs.atlas,pch=19,cex=.2,col='grey45')points(pres.atlas.real,bg='steelblue3',pch=21,cex=.7)text(22.5,-32,titles[2],cex=1.8)text(18,-31.2,lab[2],cex=1.3)  	#spacer#image(tmp1[[i]] ,col='white',xaxt='n', yaxt='n', bty='n',main='')#
for(i in 1:dim(tmp1)[3]){ image(tmp1[[i]] ,col=cols1(100,bias=.5),xaxt='n', yaxt='n', bty='n',main='',cex.main=1.5, zlim=c(0,z.max), breaks=breaks) text(22.5,-32,titles[i+2],cex=1.8) text(18,-31.2,lab[i+2],cex=1.3)	#legend if(i==1){	 image(tmp1[[2]] ,col='white',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))	 image.plot(tmp1[[2]],legend.only=TRUE,col=cols1(100,bias=.5),xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, legend.args=list(text="relative\noccurrence rate",cex=1.2),smallplot=c(.05,.95,.55,.65),zlim=range(log(breaks[-1]),na.rm=T),breaks=c(-100,log(breaks[-1])),horizontal=TRUE,axis.args=list( at=log(quantile(values(tmp1), c(.001,.3,.7,1),na.rm=T)), labels=sprintf("%.0e",quantile(values(tmp1), c(.001,.3,.7,1),na.rm=T)))) }}dev.off()if(AUREP) system('open /Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_predictions_AUREP.pdf')if(NANA) system('open /Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_predictions_NANA.pdf')
if(AUREP) pdf('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_predictions_AUREP.pdf',h=6,w=5)if(NANA) pdf('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_predictions_NANA.pdf',h=6,w=5)titles=c("Training Data","Testing Data",'Taxonomic Prior','Maxent Prediction\n(Uniform Prior)','S.D. of \n Maxent Predictions', 'Minxent Prediction\n(Taxonomic Prior)', 'S.D. of \n Minxent Predictions')par(mar=c(.2,.1,1.5,.1),mfrow=c(4,2),oma=c(0,1,0,.3))z.max=max(values(tmp1),na.rm=T)x.min=min(values(tmp1),na.rm=T)min.quant=0 # the quantile below which grey scale is used.breaks=c(-100,quantile(values(tmp1), seq(min.quant,1,length=100),na.rm=T))lab=letters[1:10]image(tmp1[[1]] ,col='grey70',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))points(pres.atlas.genus,col='red2',pch=19,cex=.5)points(pres.atlas,bg='steelblue3',pch=21,cex=.7)text(22.5,-32,titles[1],cex=1.8)text(18,-31.2,lab[1],cex=1.3)image(tmp1[[1]] ,col='grey70',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))#points(pres.atlas.genus,col='red2',pch=19,cex=.5)points(abs.atlas,pch=19,cex=.2,col='grey45')points(pres.atlas.real,bg='steelblue3',pch=21,cex=.7)text(22.5,-32,titles[2],cex=1.8)text(18,-31.2,lab[2],cex=1.3)  	#spacer#image(tmp1[[i]] ,col='white',xaxt='n', yaxt='n', bty='n',main='')#
for(i in 1:dim(tmp1)[3]){ image(tmp1[[i]] ,col=cols1(100,bias=.5),xaxt='n', yaxt='n', bty='n',main='',cex.main=1.5, zlim=c(0,z.max), breaks=breaks) text(22.5,-32,titles[i+2],cex=1.8) text(18,-31.2,lab[i+2],cex=1.3)	#legend if(i==1){	 image(tmp1[[2]] ,col='white',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))	 image.plot(tmp1[[2]],legend.only=TRUE,col=cols1(100,bias=.5),xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, legend.args=list(text="relative\noccurrence rate",cex=1.2),smallplot=c(.05,.95,.55,.65),zlim=range(log(breaks[-1]),na.rm=T),breaks=c(-100,log(breaks[-1])),horizontal=TRUE,axis.args=list( at=log(quantile(values(tmp1), c(.001,.3,.7,1),na.rm=T)), labels=sprintf("%.0e",quantile(values(tmp1), c(.001,.3,.7,1),na.rm=T)))) }}dev.off()if(AUREP) system('open /Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_predictions_AUREP.pdf')if(NANA) system('open /Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_predictions_NANA.pdf')
str(nana_naive_perf)if(NANA) pdf('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf',h=3,w=5)par(mfrow=c(1,3))plot(nana_naive_perf$cutoff,nana_naive_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='maxent')lines(nana_naive_perf$cutoff,nana_naive_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)plot(nana_minxent_perf$cutoff,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='minxent')lines(nana_minxent_perf$cutoff,nana_minxent_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)plot(1-nana_minxent_perf$specificity,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='1-specificity',ylab='sensitivity',las=1,bty='n')lines(1-nana_naive_perf$specificity,nana_naive_perf$sensitivity,lwd=3,col='steelblue3')legend('right',legend=c('minxent','maxent'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)if(NANA) system('open /Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf')
par(mfrow=c(1,3))plot(nana_naive_perf$cutoff,nana_naive_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='maxent')lines(nana_naive_perf$cutoff,nana_naive_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)plot(nana_minxent_perf$cutoff,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='minxent')lines(nana_minxent_perf$cutoff,nana_minxent_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)plot(1-nana_minxent_perf$specificity,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='1-specificity',ylab='sensitivity',las=1,bty='n')lines(1-nana_naive_perf$specificity,nana_naive_perf$sensitivity,lwd=3,col='steelblue3')legend('right',legend=c('minxent','maxent'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)
if(NANA) pdf('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf',h=3,w=5)par(mfrow=c(1,3))plot(nana_naive_perf$cutoff,nana_naive_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='maxent')lines(nana_naive_perf$cutoff,nana_naive_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)plot(nana_minxent_perf$cutoff,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='minxent')lines(nana_minxent_perf$cutoff,nana_minxent_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)plot(1-nana_minxent_perf$specificity,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='1-specificity',ylab='sensitivity',las=1,bty='n',main='ROC plot')lines(1-nana_naive_perf$specificity,nana_naive_perf$sensitivity,lwd=3,col='steelblue3')legend('right',legend=c('minxent','maxent'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)if(NANA) system('open /Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf')
pdf('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf',h=3,w=5)
if(NANA) pdf('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf',h=3,w=5)par(mfrow=c(1,3))plot(nana_naive_perf$cutoff,nana_naive_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='maxent')lines(nana_naive_perf$cutoff,nana_naive_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)plot(nana_minxent_perf$cutoff,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='minxent')lines(nana_minxent_perf$cutoff,nana_minxent_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)# plot(1-nana_minxent_perf$specificity,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='1-specificity',ylab='sensitivity',las=1,bty='n',main='ROC plot')# lines(1-nana_naive_perf$specificity,nana_naive_perf$sensitivity,lwd=3,col='steelblue3')# legend('right',legend=c('minxent','maxent'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)if(NANA) system('open /Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf')
NANA
if(NANA) pdf('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf',h=3,w=5)par(mfrow=c(1,3))plot(nana_naive_perf$cutoff,nana_naive_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='maxent')lines(nana_naive_perf$cutoff,nana_naive_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)# plot(nana_minxent_perf$cutoff,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='minxent')# lines(nana_minxent_perf$cutoff,nana_minxent_perf$specificity,lwd=3,col='steelblue3')# legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)plot(1-nana_minxent_perf$specificity,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='1-specificity',ylab='sensitivity',las=1,bty='n',main='ROC plot')lines(1-nana_naive_perf$specificity,nana_naive_perf$sensitivity,lwd=3,col='steelblue3')legend('right',legend=c('minxent','maxent'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)if(NANA) system('open /Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf')
if(NANA) pdf('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf',h=3,w=5)par(mfrow=c(1,3))# plot(nana_naive_perf$cutoff,nana_naive_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='maxent')# lines(nana_naive_perf$cutoff,nana_naive_perf$specificity,lwd=3,col='steelblue3')# legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)plot(nana_minxent_perf$cutoff,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='minxent')lines(nana_minxent_perf$cutoff,nana_minxent_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)plot(1-nana_minxent_perf$specificity,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='1-specificity',ylab='sensitivity',las=1,bty='n',main='ROC plot')lines(1-nana_naive_perf$specificity,nana_naive_perf$sensitivity,lwd=3,col='steelblue3')legend('right',legend=c('minxent','maxent'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)if(NANA) system('open /Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf')
dev.new()
par(mfrow=c(1,3))plot(nana_naive_perf$cutoff,nana_naive_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='maxent')lines(nana_naive_perf$cutoff,nana_naive_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)plot(nana_minxent_perf$cutoff,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='minxent')lines(nana_minxent_perf$cutoff,nana_minxent_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)plot(1-nana_minxent_perf$specificity,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='1-specificity',ylab='sensitivity',las=1,bty='n',main='ROC plot')lines(1-nana_naive_perf$specificity,nana_naive_perf$sensitivity,lwd=3,col='steelblue3')legend('right',legend=c('minxent','maxent'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)
if(NANA) pdf('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf',h=3,w=5)par(mfrow=c(1,3))plot(nana_naive_perf$cutoff,nana_naive_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='maxent')lines(nana_naive_perf$cutoff,nana_naive_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)plot(nana_minxent_perf$cutoff,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='minxent')lines(nana_minxent_perf$cutoff,nana_minxent_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)plot(1-nana_minxent_perf$specificity,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='1-specificity',ylab='sensitivity',las=1,bty='n',main='ROC plot')lines(1-nana_naive_perf$specificity,nana_naive_perf$sensitivity,lwd=3,col='steelblue3')legend('bottomright',legend=c('minxent','maxent'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=2)dev.off()if(NANA) system('open /Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf')
# == plot performance if(NANA) pdf('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf',h=3,w=5)par(mfrow=c(1,3))plot(nana_naive_perf$cutoff,nana_naive_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='maxent')lines(nana_naive_perf$cutoff,nana_naive_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=1)plot(nana_minxent_perf$cutoff,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='minxent')lines(nana_minxent_perf$cutoff,nana_minxent_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=1)plot(1-nana_minxent_perf$specificity,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='1-specificity',ylab='sensitivity',las=1,bty='n',main='ROC plot')lines(1-nana_naive_perf$specificity,nana_naive_perf$sensitivity,lwd=3,col='steelblue3')legend('bottomright',legend=c('minxent','maxent'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=1)dev.off()if(NANA) system('open /Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf')
if(NANA) pdf('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf',h=3,w=7)par(mfrow=c(1,3))plot(nana_naive_perf$cutoff,nana_naive_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='maxent')lines(nana_naive_perf$cutoff,nana_naive_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=1)plot(nana_minxent_perf$cutoff,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='minxent')lines(nana_minxent_perf$cutoff,nana_minxent_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=1)plot(1-nana_minxent_perf$specificity,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='1-specificity',ylab='sensitivity',las=1,bty='n',main='ROC plot')lines(1-nana_naive_perf$specificity,nana_naive_perf$sensitivity,lwd=3,col='steelblue3')legend('bottomright',legend=c('minxent','maxent'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=1)dev.off()if(NANA) system('open /Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf')
library(raster)library(fields)setwd('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/temp_sharing/Application 3 Range Maps')cols1=function(x,bias=1) { colorRampPalette(c('grey80','steelblue4','steelblue1','gold','red1','red4'),bias=bias)(x) }# cols1=function(x,bias=1) { colorRampPalette(c('grey80','steelblue4','steelblue1','gold','red1','red4'),bias=bias)(x) # }#convert maxents raw to cumulative output	#z is a vectorcumulative=function(z){   ordering=order(z,na.last=NA)   sorted=sort(z)	   cum=0*sorted   for(i in 1:length(sorted)){cum[i]=100*sum(sorted[1:i])}   z.cum=0*z   z.cum[ordering]=cum   return(z.cum)}#############################################read data ############################################PUNC=TRUEif(PUNC) { tmp1=stack('prpunc_atlas_rangemap.asc', 'prpunc_precis.asc','prpunc_precis_with_bias.asc')	pres.precis=read.csv('prpunc_precis_pnts.csv')	pres.atlas=read.csv('prpunc_protea_atlas_pnts.csv')}#make sure everything is normalizedvalues(tmp1)=apply(values(tmp1),2,function(x) {x/sum(x,na.rm=T)})coordinates(pres.precis)=c(2,3)coordinates(pres.atlas)=c(2,3)quantile(values(tmp1)[,1],seq(0,1,length=101),na.rm=T)#this should be .9sum(values(tmp1)[which(values(tmp1)[,1]>9e-06),1],na.rm=T)
library(raster)library(fields)setwd('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/temp_sharing/Application 4 Higher Order Taxon Info')cols1=function(x,bias=1) { colorRampPalette(c('grey80','grey50','steelblue4','steelblue1','steelblue1','gold','red1','red3'),bias=bias)(x) }#############################################read data ############################################(load('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/temp_sharing/protea_model_performance.RData'))AUREP=FALSE # use this for the example that doesn't work (that 1st try)if(AUREP) { 	tmp1=stack('pr_white.asc', 'praurep.asc','praurep_with_bias.asc')	#pres.atlas=read.csv('praurep_protea_atlas_pnts.csv')	pres.atlas=read.csv('p_nana_precis_occur.csv')	#pres.atlas.genus=read.csv('prwhite_protea_atlas_pnts.csv')	pres.atlas.genus=read.csv('rose_protea_no_nana_occur.csv')}NANA=TRUEif(NANA) { 	tmp1=stack('pr_rose_prior.asc', 'p_nana_precis_naive.asc','p_nana_precis_naive_stdev.asc','p_nana_minxent_avg.asc','p_nana_minxent_stdev.asc')	pres.atlas=read.csv('p_nana_precis_occur.csv')	pres.atlas.genus=read.csv('rose_protea_no_nana_occur.csv')	pres.atlas.real=read.csv('p_nana_atlas_occur.csv')	#pres.atlas.genus=read.csv('rose_protea_no_nana_occur.csv')}abs.atlas=read.csv('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Temp_sharing/Application 4 Higher Order Taxon Info/prall_train.csv') #note that this is probably all the sampling locations, wich is close enough for the picture.values(tmp1)[,c(1,2,4)]=apply(values(tmp1)[,c(1,2,4)],2,function(x) {x/sum(x,na.rm=T)})	#make a uniform prior for plotting#values(tmp1[[1]])[!is.na(values(tmp1[[1]]))]=1/sum(!is.na(values(tmp1[[1]])))#values(tmp1)[values(tmp1)<1e-10]=1e-10coordinates(pres.atlas.genus)=c(2,3)coordinates(pres.atlas)=c(2,3)coordinates(pres.atlas.real)=c(2,3)coordinates(abs.atlas)=c(2,3)
str(nana_naive_perf)
if(NANA) system('open /Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf')
par(mfrow=c(1,3))plot(nana_naive_perf$cutoff,nana_naive_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='maxent',xlim=c(0,3.5e-4))lines(nana_naive_perf$cutoff,nana_naive_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=1)plot(nana_minxent_perf$cutoff,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='minxent',xlim=c(0,3.5e-4))lines(nana_minxent_perf$cutoff,nana_minxent_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=1)plot(1-nana_minxent_perf$specificity,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='1-specificity',ylab='sensitivity',las=1,bty='n',main='ROC plot')lines(1-nana_naive_perf$specificity,nana_naive_perf$sensitivity,lwd=3,col='steelblue3')legend('bottomright',legend=c('minxent','maxent'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=1)
if(NANA) pdf('/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf',h=3,w=7)par(mfrow=c(1,3))plot(nana_naive_perf$cutoff,nana_naive_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='maxent',xlim=c(0,3.5e-4))lines(nana_naive_perf$cutoff,nana_naive_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=1)plot(nana_minxent_perf$cutoff,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='threshold',ylab='sensitivity/specificity',las=1,bty='n',main='minxent',xlim=c(0,3.5e-4))lines(nana_minxent_perf$cutoff,nana_minxent_perf$specificity,lwd=3,col='steelblue3')legend('right',legend=c('sensitivity','specificity'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=1)plot(1-nana_minxent_perf$specificity,nana_minxent_perf$sensitivity,type='l',lwd=3,col='red3',xlab='1-specificity',ylab='sensitivity',las=1,bty='n',main='ROC plot')lines(1-nana_naive_perf$specificity,nana_naive_perf$sensitivity,lwd=3,col='steelblue3')legend('bottomright',legend=c('minxent','maxent'),col=c('red3','steelblue3'),lwd=4,bty='n',cex=1)dev.off()if(NANA) system('open /Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Figures/App4_nana_ROC.pdf')
library(maptools)library(raster)species=CEORmodel.output='Maxent_output' # folder: all model runs go herefinal.model.output='Final.out' # folder: the directory of files used for the figure in ms
library(maptools)library(raster)species=CEORmodel.output='Maxent_output' # folder: all model runs go herefinal.model.output='Final.out' # folder: the directory of files used for the figure in ms################################################################################# Functions and Setup################################################################################ normalization function; ensures predicted probabilities sum to 1. norm=function(surf){ surf/sum(surf,na.rm=T)}# the following must be setup up on your own computerwd='/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Manuscript/Appendix_Data/App5-Native_Range_Info'# set where yout maxent jar file ismaxent.location='/Users/ctg/Dropbox/MaxEnt/Program/maxent.jar'setwd(wd)# automatically create places to put maxent outputif(!file.exists(model.output)) {dir.create(model.output)}# settings that apply to all models below, which will be supplied to the maxent softwareall.models=' nowarnings noprefixes -E responsecurves jackknife outputformat=raw removeduplicates noaskoverwrite -a -z threads=3 replicates=5 nothreshold nohinge noautofeature '
bias_TG_PRDB=paste0('java -jar ',maxent.location, all.models, ' -N bio3 -N bio4 -N bio5 -N bio12 ')output=paste0(wd,'/',model.output,'/Japan_TG_bias')if(!file.exists(output)) {dir.create(output)}environmental=paste0(wd,'/Japan_ASCII')samples=paste0(wd,'/Bias_PRDB_allPoints.csv')system(paste0(bias_TG_PRDB,'outputdirectory=',output,' environmentallayers=',environmental,' samplesfile=',samples))
NE_noBias_C=paste0('java -jar ',maxent.location, all.models, ' -N pop_max -N roads_max ')output=paste0(wd,'/',model.output,'/',species,'_NE_noBias')if(!file.exists(output)) {dir.create(output)}environmental=paste0(wd,'/NE_ASCII')samples=paste0(wd,'/',species,'_IPANE_5min_nodup.csv')
species='CEOR'
Japan_TGbias_C=paste0('java -jar ',maxent.location, all.models, ' -N pop_max -N roads_max biastype=3 ')output=paste0(wd,'/',model.output,'/',species,'_Japan_NEproj')if(!file.exists(output)) {dir.create(output)}environmental=paste0(wd,'/Japan_ASCII')samples=paste0(wd,'/PRDB_',species,'_5min_points.csv')bias=paste0(wd,'/',model.output,'/JAPAN_TG_bias/bias_avg.asc')projection=paste0(wd,'/NE_ASCII')system(paste0(Japan_TGbias_C,'outputdirectory=',output,' environmentallayers=',environmental,' samplesfile=',samples,' biasfile=',bias, ' projectionlayers=',projection))
all.models=' nowarnings noprefixes -E jackknife outputformat=raw removeduplicates noaskoverwrite -a -z threads=3 replicates=5 nothreshold nohinge noautofeature '
Japan_TGbias_C=paste0('java -jar ',maxent.location, all.models, ' -N pop_max -N roads_max biastype=3 ')output=paste0(wd,'/',model.output,'/',species,'_Japan_NEproj')if(!file.exists(output)) {dir.create(output)}environmental=paste0(wd,'/Japan_ASCII')samples=paste0(wd,'/PRDB_',species,'_5min_points.csv')bias=paste0(wd,'/',model.output,'/JAPAN_TG_bias/bias_avg.asc')projection=paste0(wd,'/NE_ASCII')system(paste0(Japan_TGbias_C,'outputdirectory=',output,' environmentallayers=',environmental,' samplesfile=',samples,' biasfile=',bias, ' projectionlayers=',projection))#
# =========================================================================## run MaxEnt for IPANE dataset with TG sampling biasNE_TGbias_C=paste0('java -jar ',maxent.location, all.models,' -N pop_max -N roads_max biastype=3 ')output=paste0(wd,'/',model.output,'/',species,'_NE_withTGbias')if(!file.exists(output)) {dir.create(output)}environmental=paste0(wd,'/NE_ASCII')samples=paste0(wd,'/',species,'_IPANE_5min_nodup.csv')bias=paste0(wd,'/',model.output,'/IPANE_TG_bias/bias_avg.asc')system(paste0(NE_TGbias_C,'outputdirectory=',output,' environmentallayers=',environmental,' samplesfile=',samples,' biasfile=',bias))
all.models=' nowarnings noprefixes -E outputformat=raw removeduplicates noaskoverwrite -a -z threads=3 replicates=5 nothreshold nohinge noautofeature '
NE_noBias_nativePrior_C=paste0('java -jar ',maxent.location, all.models,' -N pop_max -N roads_max biastype=3 ')output=paste0(wd,'/',model.output,'/',species,'_NE_JapanPrior')if(!file.exists(output)) {dir.create(output)}environmental=paste0(wd,'/NE_ASCII')samples=paste0(wd,'/',species,'_IPANE_5min_nodup.csv')bias=paste0(wd,'/',model.output,'/',species,'_Japan_NEproj/',species,'_NE_ASCII_avg.asc')system(paste0(NE_noBias_nativePrior_C,'outputdirectory=',output,' environmentallayers=',environmental,' samplesfile=',samples,' biasfile=',bias))
all.models=' nowarnings noprefixes responsecurves jackknife outputformat=raw removeduplicates noaskoverwrite -a -z threads=3 replicates=5 nothreshold nohinge noautofeature '
bias_TG_IPANE=paste0('java -jar ',maxent.location, all.models,' -N bio3 -N bio4 -N bio5 -N bio12 ')output=paste0(wd,'/',model.output,'/IPANE_TG_bias')if(!file.exists(output)) {dir.create(output)}environmental=paste0(wd,'/NE_ASCII')samples=paste0(wd,'/Bias_IPANE_allPoints.csv')system(paste0(bias_TG_IPANE,'outputdirectory=',output,' environmentallayers=',environmental,' samplesfile=',samples))## note that you'll see some errors from points missing evnironmental data## target group sampling bias based on anthropogenic predictors for PRDB data (Japan)bias_TG_PRDB=paste0('java -jar ',maxent.location, all.models, ' -N bio3 -N bio4 -N bio5 -N bio12 ')output=paste0(wd,'/',model.output,'/Japan_TG_bias')if(!file.exists(output)) {dir.create(output)}environmental=paste0(wd,'/Japan_ASCII')samples=paste0(wd,'/Bias_PRDB_allPoints.csv')system(paste0(bias_TG_PRDB,'outputdirectory=',output,' environmentallayers=',environmental,' samplesfile=',samples))
NE_noBias_C=paste0('java -jar ',maxent.location, all.models, ' -N pop_max -N roads_max ')output=paste0(wd,'/',model.output,'/',species,'_NE_noBias')if(!file.exists(output)) {dir.create(output)}environmental=paste0(wd,'/NE_ASCII')samples=paste0(wd,'/',species,'_IPANE_5min_nodup.csv')system(paste0(NE_noBias_C,'outputdirectory=',output,' environmentallayers=',environmental,' samplesfile=',samples))# =========================================================================## run Japan model with TG sampling bias, project to NEJapan_TGbias_C=paste0('java -jar ',maxent.location, all.models, ' -N pop_max -N roads_max biastype=3 ')output=paste0(wd,'/',model.output,'/',species,'_Japan_NEproj')if(!file.exists(output)) {dir.create(output)}environmental=paste0(wd,'/Japan_ASCII')samples=paste0(wd,'/PRDB_',species,'_5min_points.csv')bias=paste0(wd,'/',model.output,'/JAPAN_TG_bias/bias_avg.asc')projection=paste0(wd,'/NE_ASCII')system(paste0(Japan_TGbias_C,'outputdirectory=',output,' environmentallayers=',environmental,' samplesfile=',samples,' biasfile=',bias, ' projectionlayers=',projection))
NE_TGbias_C=paste0('java -jar ',maxent.location, all.models,' -N pop_max -N roads_max biastype=3 ')output=paste0(wd,'/',model.output,'/',species,'_NE_withTGbias')if(!file.exists(output)) {dir.create(output)}environmental=paste0(wd,'/NE_ASCII')samples=paste0(wd,'/',species,'_IPANE_5min_nodup.csv')bias=paste0(wd,'/',model.output,'/IPANE_TG_bias/bias_avg.asc')system(paste0(NE_TGbias_C,'outputdirectory=',output,' environmentallayers=',environmental,' samplesfile=',samples,' biasfile=',bias))
# =========================================================================## run MaxEnt for IPANE dataset with no sampling bias and native range priorNE_noBias_nativePrior_C=paste0('java -jar ',maxent.location, all.models,' -N pop_max -N roads_max biastype=3 ')output=paste0(wd,'/',model.output,'/',species,'_NE_JapanPrior')if(!file.exists(output)) {dir.create(output)}environmental=paste0(wd,'/NE_ASCII')samples=paste0(wd,'/',species,'_IPANE_5min_nodup.csv')bias=paste0(wd,'/',model.output,'/',species,'_Japan_NEproj/',species,'_NE_ASCII_avg.asc')system(paste0(NE_noBias_nativePrior_C,'outputdirectory=',output,' environmentallayers=',environmental,' samplesfile=',samples,' biasfile=',bias))
b=readAsciiGrid(paste0(wd,'/',model.output,'/',species,'_Japan_NEproj/',species,'_NE_ASCII_avg.asc')) #CEOR Japan projection to NE#b[[2]]=readAsciiGrid('C:/Users/Jenica/Desktop/Priors_MaxEnt_Output/App6_rerun/BETH_Japan_NEproj/BETH_NE_ASCII_avg.asc')[[1]] #BETH Japan projection to NEb[[2]]=readAsciiGrid(paste0(wd,'/',model.output,'/IPANE_TG_bias/bias_avg.asc'))[[1]] #IPANE TG sampling bias modelb[[3]]=norm(b[[1]]*b[[2]])  #CEOR combined priorwrite.asciigrid(b[3], paste0(model.output,'/',species,'_NE_combined_prior.asc'))
NE_cp_C=paste0('java -jar ',maxent.location, all.models,' -N pop_max -N roads_max biastype=3 ')output=paste0(wd,'/',model.output,'/',species,'_NE_CombinedPrior')if(!file.exists(output)) {dir.create(output)}environmental=paste0(wd,'/NE_ASCII')samples=paste0(wd,'/',species,'_IPANE_5min_nodup.csv')bias=paste0(wd,'/',model.output,'/',species,'_Japan_NEproj/',species,'_NE_ASCII_avg.asc')system(paste0(NE_cp_C,'outputdirectory=',output,' environmentallayers=',environmental,' samplesfile=',samples,' biasfile=', bias))
b=stack(c(paste0(paste0(wd,'/',model.output,'/',species),c(	paste0('_NE_JapanPrior/',species,'_avg.asc'), #CEOR model with native range prior, no sampling bias 	paste0('_Japan_NEproj/',species,'_NE_ASCII_avg.asc'), #CEOR Japan projection to NE	paste0('_NE_noBias/',species,'_avg.asc'), #CEOR model with no sampling bias 	paste0('_NE_withTGbias/',species,'_avg.asc'),## CEOR NE models with sampling bias model included	paste0('_NE_CombinedPrior/',species,'_avg.asc'))), ## CEOR NE combined prior model	paste0(wd,'/',model.output,'/IPANE_TG_bias/bias_avg.asc') #IPANE TG sampling bias model 	))	names(b)=c('native.minxent.raw','native.prior','maxent.pred','sampling.minxent.pred','native.sampling.minxent.raw','sampling.prior')# modify the relevant parts of the output by multiplying by the right priorsb$native.minxent.pred=b[['native.minxent.raw']]*b[['native.prior']]  #CEOR factor Japan prior back into model without sampling biasb$native.sampling.prior=b[['sampling.prior']]*b[['native.prior']] #CEOR Combined native range * TG sampling bias priorb$native.sampling.minxent.pred=b[['native.sampling.minxent.raw']]*b[['native.prior']] #CEOR factor Japan prior back into model with sampling biasvalues(b)=apply(values(b),2,norm)
if(!file.exists(final.model.out)) dir.create(final.model.out)writeRaster(b[['native.minxent.pred']],file=paste0( 'Final_out/',species,'_NE_noBias_withNativePrior_norm.asc'),format='ascii',overwrite=T) ## CEOR NE model with no sampling bias, native prior factored back inwriteRaster(b[['maxent.pred']],file=paste0( 'Final_out/',species,  '_NE_noBias_noNativePrior_norm.asc'),format='ascii',overwrite=T) ## CEOR NE model with no sampling bias, no native range priorwriteRaster(b[['native.prior']],file=paste0( 'Final_out/',species,  '_NE_Japan_prediction_norm.asc'),format='ascii',overwrite=T) ## CEOR Japan model projected to NEwriteRaster(b[['sampling.prior']],file=paste0( 'Final_out/',  'IPANE_TG_sampling_bias_norm.asc'),format='ascii',overwrite=T) ## IPANE TG sampling bias modelwriteRaster(b[['sampling.minxent.pred']],file=paste0( 'Final_out/',species,   '_NE_withSamplingBias_norm.asc'),format='ascii',overwrite=T) #CEOR NE model that includes IPANE TG sampling biaswriteRaster(b[['native.sampling.prior']],file=paste0( 'Final_out/',species,  '_NE_CombinedPriorSurface_norm.asc'),format='ascii',overwrite=T) ## CEOR combined prior writeRaster(b[['native.sampling.minxent.pred']],file=paste0( 'Final_out/',species,  '_NE_CombinedPrior_prediction_norm.asc'),format='ascii',overwrite=T) ## CEOR combined prior prediction, with Japan factored back in
paste0( 'Final_out/',species,'_NE_noBias_withNativePrior_norm.asc')
if(!file.exists(final.model.out)) dir.create(final.model.out)
if(!file.exists(final.model.out)) dir.create(final.model.output)
writeRaster(b[['native.minxent.pred']],file=paste0( 'Final_out/',species,'_NE_noBias_withNativePrior_norm.asc'),format='ascii',overwrite=T) ## CEOR NE model with no sampling bias, native prior factored back inwriteRaster(b[['maxent.pred']],file=paste0( 'Final_out/',species,  '_NE_noBias_noNativePrior_norm.asc'),format='ascii',overwrite=T) ## CEOR NE model with no sampling bias, no native range priorwriteRaster(b[['native.prior']],file=paste0( 'Final_out/',species,  '_NE_Japan_prediction_norm.asc'),format='ascii',overwrite=T) ## CEOR Japan model projected to NEwriteRaster(b[['sampling.prior']],file=paste0( 'Final_out/',  'IPANE_TG_sampling_bias_norm.asc'),format='ascii',overwrite=T) ## IPANE TG sampling bias modelwriteRaster(b[['sampling.minxent.pred']],file=paste0( 'Final_out/',species,   '_NE_withSamplingBias_norm.asc'),format='ascii',overwrite=T) #CEOR NE model that includes IPANE TG sampling biaswriteRaster(b[['native.sampling.prior']],file=paste0( 'Final_out/',species,  '_NE_CombinedPriorSurface_norm.asc'),format='ascii',overwrite=T) ## CEOR combined prior writeRaster(b[['native.sampling.minxent.pred']],file=paste0( 'Final_out/',species,  '_NE_CombinedPrior_prediction_norm.asc'),format='ascii',overwrite=T) ## CEOR combined prior prediction, with Japan factored back in#=====================================================================## plotting
final.model.output
final.model.output='Final.out' # folder: the directory of files used for the figure in ms
final.model.output='Final_out' # folder: the directory of files used for the figure in ms
if(!file.exists(final.model.output)) dir.create(final.model.output)
writeRaster(b[['native.minxent.pred']],file=paste0( 'Final_out/',species,'_NE_noBias_withNativePrior_norm.asc'),format='ascii',overwrite=T) ## CEOR NE model with no sampling bias, native prior factored back inwriteRaster(b[['maxent.pred']],file=paste0( 'Final_out/',species,  '_NE_noBias_noNativePrior_norm.asc'),format='ascii',overwrite=T) ## CEOR NE model with no sampling bias, no native range priorwriteRaster(b[['native.prior']],file=paste0( 'Final_out/',species,  '_NE_Japan_prediction_norm.asc'),format='ascii',overwrite=T) ## CEOR Japan model projected to NEwriteRaster(b[['sampling.prior']],file=paste0( 'Final_out/',  'IPANE_TG_sampling_bias_norm.asc'),format='ascii',overwrite=T) ## IPANE TG sampling bias modelwriteRaster(b[['sampling.minxent.pred']],file=paste0( 'Final_out/',species,   '_NE_withSamplingBias_norm.asc'),format='ascii',overwrite=T) #CEOR NE model that includes IPANE TG sampling biaswriteRaster(b[['native.sampling.prior']],file=paste0( 'Final_out/',species,  '_NE_CombinedPriorSurface_norm.asc'),format='ascii',overwrite=T) ## CEOR combined prior writeRaster(b[['native.sampling.minxent.pred']],file=paste0( 'Final_out/',species,  '_NE_CombinedPrior_prediction_norm.asc'),format='ascii',overwrite=T) ## CEOR combined prior prediction, with Japan factored back in
cols1=function(x,bias=1) { colorRampPalette(c('steelblue4','steelblue1','gold','goldenrod1','red1','red4'),bias=bias)(x) }CEOR=TRUE; BETH=FALSEUS_version=FALSE
getwd()
tmp1=stack(paste0(paste0(getwd(),"/"),c('IPANE_TG_sampling_bias_norm.asc', 'CEOR_NE_withSamplingBias_norm.asc','CEOR_NE_CombinedPriorSurface_norm.asc','CEOR_NE_CombinedPrior_prediction_norm.asc')))
path=paste0(getwd(),"/")
path=paste0(getwd(),"Final_out/")
path
path=paste0(getwd(),"/Final_out/")
s
tmp1=stack(paste0(path,c('IPANE_TG_sampling_bias_norm.asc', 'CEOR_NE_withSamplingBias_norm.asc','CEOR_NE_CombinedPriorSurface_norm.asc','CEOR_NE_CombinedPrior_prediction_norm.asc')))
values(tmp1)=apply(values(tmp1),2,function(x) {x/sum(x,na.rm=T)})
pdf(paste0(path,'App6_predictions_CEOR.pdf'),h=9,w=6)titles=rep('',10)par(mar=c(.2,.1,1.5,.1),mfrow=c(3,2),oma=c(0,6,3,.2))z.max=max(values(tmp1),na.rm=T)min.quant=0 # the quantile below which grey scale is used.breaks=c(-100,quantile(values(tmp1), seq(min.quant,1,length=100),na.rm=T))lab=letters[1:10]for(i in 1:dim(tmp1)[3]){ image(tmp1[[i]] ,col=cols1(100,bias=1),xaxt='n', yaxt='n', bty='n',main=titles[i],cex.main=2.2, zlim=c(0,z.max), breaks=breaks) text(-73,47,lab[i],cex=1.3)}lab.ats=c(1-.165,.5)mtext('Samping\nPrior\n\n',2,at=lab.ats[1],outer=T,line=0,las=1)mtext('Samping\nPrior +\n Native\nRange\nPrior',2,at=lab.ats[2],outer=T,line=0,las=1)mtext('Prior',3,at=.25,outer=T,line=0)mtext('Prediction',3,at=.75,outer=T,line=0)# add legendimage(tmp1[[2]] ,col='white',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max))image.plot(tmp1[[2]],legend.only=TRUE,col=cols1(100,bias=1),xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, legend.args=list(text="relative\noccurrence rate",cex=1.2),smallplot=c(0,1,.55,.65),zlim=range(log(breaks[-1]),na.rm=T),breaks=c(-100,log(breaks[-1])),horizontal=TRUE,axis.args=list( at=log(quantile(values(tmp1), c(0,.05,.5,1),na.rm=T)), labels=sprintf("%.0e",quantile(values(tmp1), c(0,.05,.5,1),na.rm=T))))dev.off()
system(paste0('open ',path,'App6_predictions_CEOR.pdf'))
setwd('/Users/ctg/Dropbox/MaxEnt/Maxent_w_Priors/Demos/Dispersal_Demo')# automatically creat places to put maxent outputif(!file.exists('Maxent_output')) {dir.create('Maxent_output')}if(!file.exists('Maxent_output/Default')) {dir.create('Maxent_output/Default')}if(!file.exists('Maxent_output/Prior')) {dir.create('Maxent_output/Prior')}# set where yout maxent jar file ismaxent.location='../../../Program/maxent.jar'######################################################################### Load in results so I don't have to run the models below######################################################################	# load a raster brick with the predictions from another model (the dispersal model from Merow et al. 2011, Am Nat).(load(paste0(getwd(),'/Dispersal_Prior_Raster.rdata')))	# load a list of the occurrence data split up by observation year. the first element is all points observed by 1940, the second element is all points observed by 1960, etc.(load(paste0(getwd(),'/data_by_year.rdata')))
run.default=paste0('java -jar ',maxent.location, ' nowarnings noprefixes -e NE_environmental_grids  nowarnings  threads=3 testsamplesfile=CEOR_pres_All.csv nowriteclampgrid nowritemess noaskoverwrite -q -p -h nothreshold noautofeature noresponsecurves  outputformat=raw -a -z')	#1980system(paste(run.default,'-o Maxent_output/Default -s ceor_pres1980.csv'))me.unif=raster('Maxent_output/Default/CEOR.asc')
run.prior=paste0('java -jar ',maxent.location,' nowarnings noprefixes -e NE_environmental_grids testsamplesfile=CEOR_pres_All.csv nowriteclampgrid nowritemess noaskoverwrite -q -p nothreshold -h noautofeature noresponsecurves  outputformat=raw -a -z ')	#1980system(paste(run.prior,'-o Maxent_output/Prior -s ceor_pres1980.csv biasfile=CEOR1980.asc biastype=3'))	me.pot=raster('Maxent_output/Prior/CEOR.asc')
me.real=me.potvalues(me.real)=values(me.real)*values(disp.prior)[,1]values(me.real)=values(me.real)/sum(values(me.real),na.rm=T)
pdf('CEOR_All_Dispersal_Priors_Demo.pdf',h=10,w=1.8) titles=c("1980") par(mar=c(.2,.1,1.5,.1),mfrow=c(5,1),oma=c(0,3,0,.2)) tmp1=stack(me.unif,me.pot,me.real,disp.prior) z.max=max(values(tmp1),na.rm=T) breaks=c(-100,quantile(values(tmp1), seq(.25,1,length=100),na.rm=T)) image(disp.prior[[3]] ,col=cols1(100),xaxt='n', yaxt='n', bty='n',main=titles[i],cex.main=2.2, zlim=c(0,z.max), breaks=breaks) tmp=data.by.year[[3]] coordinates(tmp)=c(2,3) points(tmp,col='black',pch=19,cex=.5) image(me.unif[[1]] ,col=cols1(100),xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max), breaks=breaks)  tmp=read.csv('CEOR_pres_All.csv')	coordinates(tmp)=c(2,3)	points(tmp,col='black',pch=19,cex=.5) image(me.pot[[1]] ,col=cols1(100),xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max), breaks=breaks)  tmp=read.csv('CEOR_pres_All.csv')	coordinates(tmp)=c(2,3)	points(tmp,col='black',pch=19,cex=.5) image(me.real[[1]] ,col=cols1(100),xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max),breaks=breaks) 	tmp=data.by.year[[3]]	coordinates(tmp)=c(2,3)	points(tmp,col='black',pch=19,cex=.5) mtext('Minxent\nRealized Distribution',2,at=.3,outer=T,line=0) mtext('Minxent\nPotential Distribution',2,at=.5,outer=T,line=0) mtext('Dispersal Model\n(Prior)',2,at=.9,outer=T,line=0) mtext('Maxent (Uniform Prior)\nPotential Distribution',2,at=.7,outer=T,line=0) # add legend image(me.real[[i]] ,col='white',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max)) image.plot(me.real[[i]],legend.only=TRUE,col=cols1(100),xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, legend.args=list(text="relative\noccurrence rate",cex=1.2),smallplot=c(0,.9,.75,.85),zlim=range(log(breaks[-1])),breaks=c(-100,log(breaks[-1])),horizontal=TRUE,axis.args=list( at=log(quantile(values(tmp1), c(.01,.35,.75,1),na.rm=T)), labels=c('0','1e-5','3e-4','2e-2')))dev.off()system('open CEOR_All_Dispersal_Priors_Demo.pdf')
pdf('CEOR_All_Dispersal_Priors_Demo.pdf',h=10,w=1.8) titles=c("1980") par(mar=c(.2,.1,1.5,.1),mfrow=c(5,1),oma=c(0,3,0,.2)) tmp1=stack(me.unif,me.pot,me.real,disp.prior) z.max=max(values(tmp1),na.rm=T) breaks=c(-100,quantile(values(tmp1), seq(.25,1,length=100),na.rm=T)) image(disp.prior[[3]] ,col=cols1(100),xaxt='n', yaxt='n', bty='n',main=titles[i],cex.main=2.2, zlim=c(0,z.max), breaks=breaks) tmp=data.by.year[[3]] coordinates(tmp)=c(2,3) points(tmp,col='black',pch=19,cex=.5) image(me.unif[[1]] ,col=cols1(100),xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max), breaks=breaks)  tmp=read.csv('CEOR_pres_All.csv')	coordinates(tmp)=c(2,3)	points(tmp,col='black',pch=19,cex=.5) image(me.pot[[1]] ,col=cols1(100),xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max), breaks=breaks)  tmp=read.csv('CEOR_pres_All.csv')	coordinates(tmp)=c(2,3)	points(tmp,col='black',pch=19,cex=.5) image(me.real[[1]] ,col=cols1(100),xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max),breaks=breaks) 	tmp=data.by.year[[3]]	coordinates(tmp)=c(2,3)	points(tmp,col='black',pch=19,cex=.5) mtext('Minxent\nRealized Distribution',2,at=.3,outer=T,line=0) mtext('Minxent\nPotential Distribution',2,at=.5,outer=T,line=0) mtext('Dispersal Model\n(Prior)',2,at=.9,outer=T,line=0) mtext('Maxent (Uniform Prior)\nPotential Distribution',2,at=.7,outer=T,line=0) # add legend image(me.real[[i]] ,col='white',xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, zlim=c(0,z.max)) image.plot(me.real[[i]],legend.only=TRUE,col=cols1(100),xaxt='n', yaxt='n', bty='n',main='',cex.main=2.2, legend.args=list(text="relative\noccurrence rate",cex=1.2),smallplot=c(0,.9,.75,.85),zlim=range(log(breaks[-1])),breaks=c(-100,log(breaks[-1])),horizontal=TRUE,axis.args=list( at=log(quantile(values(tmp1), c(.01,.35,.75,1),na.rm=T)), labels=c('0','1e-5','3e-4','2e-2')))dev.off()system('open CEOR_All_Dispersal_Priors_Demo.pdf')# note that the colors are slightly different from those in the main text because the quantiles of the predictions are used for the color scale and the quantile of the predictions aggregated across all time steps differ from those for models from just 1980.
library(maptools)library(raster)species='CEOR'model.output='Maxent_output' # folder: all model runs go herefinal.model.output='Final_out' # folder: the directory of files used for the figure in ms################################################################################# Functions and Setup################################################################################ normalization function; ensures predicted probabilities sum to 1. norm=function(surf){ surf/sum(surf,na.rm=T)}# the following must be setup up on your own computerwd='/Users/ctg/Dropbox/Projects/Maxent_Priors_MS/Manuscript/Appendix_Data/App1-Sampling_Bias'# set where yout maxent jar file ismaxent.location='/Users/ctg/Dropbox/MaxEnt/Program/maxent.jar'setwd(wd)# automatically create places to put maxent outputif(!file.exists(model.output)) {dir.create(model.output)}# settings that apply to all models below, which will be supplied to the maxent softwareall.models=' nowarnings noprefixes responsecurves jackknife outputformat=raw removeduplicates noaskoverwrite -a -z threads=3 replicates=5 nothreshold nohinge noautofeature '
bias_TG_IPANE=paste0('java -jar ',maxent.location, all.models,' -N bio3 -N bio4 -N bio5 -N bio12 ')output=paste0(wd,'/',model.output,'/IPANE_TG_bias')if(!file.exists(output)) {dir.create(output)}environmental=paste0(wd,'/NE_ASCII')samples=paste0(wd,'/Bias_IPANE_allPoints.csv')system(paste0(bias_TG_IPANE,'outputdirectory=',output,' environmentallayers=',environmental,' samplesfile=',samples))
NE_noBias_C=paste0('java -jar ',maxent.location, all.models, ' -N pop_max -N roads_max ')output=paste0(wd,'/',model.output,'/',species,'_NE_noBias')if(!file.exists(output)) {dir.create(output)}environmental=paste0(wd,'/NE_ASCII')samples=paste0(wd,'/',species,'_IPANE_5min_nodup.csv')system(paste0(NE_noBias_C,'outputdirectory=',output,' environmentallayers=',environmental,' samplesfile=',samples))
## run MaxEnt for IPANE dataset with Target group sampling biasNE_TGbias_C=paste0('java -jar ',maxent.location, all.models,' -N pop_max -N roads_max biastype=3 ')output=paste0(wd,'/',model.output,'/',species,'_NE_withTGbias')if(!file.exists(output)) {dir.create(output)}environmental=paste0(wd,'/NE_ASCII')samples=paste0(wd,'/',species,'_IPANE_5min_nodup.csv')bias=paste0(wd,'/',model.output,'/IPANE_TG_bias/bias_avg.asc')system(paste0(NE_TGbias_C,'outputdirectory=',output,' environmentallayers=',environmental,' samplesfile=',samples,' biasfile=',bias))
b=stack(c(paste0(paste0(wd,'/',model.output,'/',species),c(	paste0('_NE_noBias/',species,'_avg.asc'), #CEOR model with no sampling bias 	paste0('_NE_withTGbias/',species,'_avg.asc'),## CEOR NE models with sampling bias model included	paste0(wd,'/',model.output,'/IPANE_TG_bias/bias_avg.asc') #IPANE TG sampling bias model 	))
)))
c(paste0(paste0(wd,'/',model.output,'/',species),c(	paste0('_NE_noBias/',species,'_avg.asc'), #CEOR model with no sampling bias 	paste0('_NE_withTGbias/',species,'_avg.asc'),## CEOR NE models with sampling bias model included	paste0(wd,'/',model.output,'/IPANE_TG_bias/bias_avg.asc') #IPANE TG sampling bias model 	)))
c(	paste0('_NE_noBias/',species,'_avg.asc'), #CEOR model with no sampling bias 	paste0('_NE_withTGbias/',species,'_avg.asc'),## CEOR NE models with sampling bias model included	paste0(wd,'/',model.output,'/IPANE_TG_bias/bias_avg.asc') #IPANE TG sampling bias model 	)
c(paste0(paste0(wd,'/',model.output,'/',species),c(	paste0('_NE_noBias/',species,'_avg.asc'), #CEOR model with no sampling bias 	paste0('_NE_withTGbias/',species,'_avg.asc'),## CEOR NE models with sampling bias model included	paste0(wd,'/',model.output,'/IPANE_TG_bias/bias_avg.asc') #IPANE TG sampling bias model 	))
paste0(paste0(wd,'/',model.output,'/',species)
b=stack(c(paste0(paste0(wd,'/',model.output,'/',species),c(	paste0('_NE_noBias/',species,'_avg.asc'), #CEOR model with no sampling bias 	paste0('_NE_withTGbias/',species,'_avg.asc'),## CEOR NE models with sampling bias model included	paste0(wd,'/',model.output,'/IPANE_TG_bias/bias_avg.asc') #IPANE TG sampling bias model 	))))
species
paste0(wd,'/',model.output,'/',species),c(	paste0('_NE_noBias/',species,'_avg.asc'), #CEOR model with no sampling bias 	paste0('_NE_withTGbias/',species,'_avg.asc'),## CEOR NE models with sampling bias model included	paste0(wd,'/',model.output,'/IPANE_TG_bias/bias_avg.asc') #IPANE TG sampling bias model 	))
paste0(wd,'/',model.output,'/',species),c(	paste0('_NE_noBias/',species,'_avg.asc'), #CEOR model with no sampling bias 	paste0('_NE_withTGbias/',species,'_avg.asc'),## CEOR NE models with sampling bias model included	paste0(wd,'/',model.output,'/IPANE_TG_bias/bias_avg.asc') #IPANE TG sampling bias model 	)
c(	paste0('_NE_noBias/',species,'_avg.asc'), #CEOR model with no sampling bias 	paste0('_NE_withTGbias/',species,'_avg.asc'),## CEOR NE models with sampling bias model included	paste0(wd,'/',model.output,'/IPANE_TG_bias/bias_avg.asc')
paste0(	paste0(wd,'/',model.output,'/',species),c(	paste0('_NE_noBias/',species,'_avg.asc'), #CEOR model with no sampling bias 	paste0('_NE_withTGbias/',species,'_avg.asc'))
paste0('_NE_JapanPrior/',species,'_avg.asc')
paste0('_Japan_NEproj/',species,'_NE_ASCII_avg.asc'), #CEOR Japan projection to NE
b=stack(c(paste0(paste0(wd,'/',model.output,'/',species),c(	paste0('_NE_noBias/',species,'_avg.asc'), #CEOR model with no sampling bias 	paste0('_NE_withTGbias/',species,'_avg.asc'),## CEOR NE models with sampling bias model included	paste0('_NE_CombinedPrior/',species,'_avg.asc'))), ## CEOR NE combined prior model	paste0(wd,'/',model.output,'/IPANE_TG_bias/bias_avg.asc') #IPANE TG sampling bias model 	))
b=stack(c(paste0(paste0(wd,'/',model.output,'/',species),c(	paste0('_NE_noBias/',species,'_avg.asc'), #CEOR model with no sampling bias 	paste0('_NE_withTGbias/',species,'_avg.asc')## CEOR NE models with sampling bias model included	)),	paste0(wd,'/',model.output,'/IPANE_TG_bias/bias_avg.asc') #IPANE TG sampling bias model 	))
names(b)=c('maxent.pred','sampling.minxent.pred','sampling.prior')
values(b)=apply(values(b),2,norm)
plot(b)
3718/2
1859+1700
(3.8+7.7)/(7.2+8.7)
(3.8+7.7+3.8)/(7.2+8.7+4.2)
